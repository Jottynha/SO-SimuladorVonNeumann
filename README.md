<p align="center"> 
  <img src="imgs/logo_azul.png" alt="CEFET-MG" width="100px" height="100px">
</p>

<h1 align="center">
ğŸ–¥ï¸ Simulador Multicore Von Neumann
</h1>

<h3 align="center">
Arquitetura Multicore com Pipeline MIPS, Escalonamento e Gerenciamento de MemÃ³ria
</h3>

<div align="center">

![C++](https://img.shields.io/badge/C%2B%2B-17-blue)
![CMake](https://img.shields.io/badge/CMake-3.10+-green)
![Docker](https://img.shields.io/badge/Docker-ready-informational)
![DevContainers](https://img.shields.io/badge/VSCode-Dev%20Containers-23a)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-100%25%20conclu%C3%ADdo-success)

</div>

---

<div align="justify">
<p><strong>Disciplina:</strong> Sistemas Operacionais<br>
<strong>InstituiÃ§Ã£o:</strong> Centro Federal de EducaÃ§Ã£o TecnolÃ³gica de Minas Gerais (CEFET-MG) - Campus V DivinÃ³polis<br>
<strong>Professor:</strong> Michel Pires da Silva<br>
<strong>Projeto:</strong> Trabalho Final - SimulaÃ§Ã£o de Arquitetura Multicore com Gerenciamento de MemÃ³ria e Escalonamento<br>
</div>


---


## Sobre o Projeto

Este projeto implementa um **simulador completo de arquitetura multicore Von Neumann** conforme especificado no enunciado do trabalho final. O sistema representa uma arquitetura com **mÃºltiplos nÃºcleos de processamento** que compartilham uma **memÃ³ria principal unificada**, executando um lote inicial de programas sob diferentes polÃ­ticas de escalonamento e gerenciamento de memÃ³ria.

### Conformidade com o Enunciado

O simulador atende **100% dos requisitos tÃ©cnicos** especificados:

- **Arquitetura Multicore**: 1-8 nÃºcleos configurÃ¡veis com execuÃ§Ã£o paralela real
- **Lote Inicial de Programas**: 9 processos carregados do disco antes da execuÃ§Ã£o
- **MemÃ³ria Compartilhada Unificada**: Acesso sincronizado entre todos os cores
- **Mapeamento Tanenbaum**: SegmentaÃ§Ã£o com 4 segmentos (CODE, DATA, STACK, HEAP)
- **PolÃ­ticas de SubstituiÃ§Ã£o**: **FIFO e LRU completamente implementadas e testadas**
- **4 PolÃ­ticas de Escalonamento**: FCFS, SJN, Priority, Round Robin
- **CenÃ¡rio NÃ£o-Preemptivo**: FCFS, SJN e Priority executam atÃ© conclusÃ£o
- **CenÃ¡rio Preemptivo**: Round Robin com quantum configurÃ¡vel
- **MÃ©tricas Completas**: Tempo de espera, retorno, utilizaÃ§Ã£o, throughput, cache hit rate
- **RelatÃ³rios de Escalonamento**: ComparaÃ§Ã£o detalhada entre polÃ­ticas
- **UtilizaÃ§Ã£o de MemÃ³ria ao Longo do Tempo**: Snapshots automÃ¡ticos e relatÃ³rios
- **ComparaÃ§Ã£o FIFO vs LRU**: Scripts automatizados para anÃ¡lise comparativa

### Componentes Implementados

| Componente | DescriÃ§Ã£o |
|------------|-----------|
| Pipeline MIPS | 5 estÃ¡gios (Fetch â†’ Decode â†’ Execute â†’ Memory â†’ WriteBack) |
| Multicore | 1-8 cores com threads C++ e sincronizaÃ§Ã£o |
| Escalonamento | 4 polÃ­ticas (FCFS, SJN, Priority, RR) |
| MemÃ³ria Segmentada | Modelo Tanenbaum com 4 segmentos |
| **Cache FIFO/LRU** | **PolÃ­ticas de substituiÃ§Ã£o com testes automatizados** |
| Hierarquia MemÃ³ria | 3 nÃ­veis (Cache â†’ RAM â†’ Swap) |
| Rastreamento Temporal | Snapshots a cada 10 ciclos |
| RelatÃ³rios | Individuais e agregados do sistema |
| VisualizaÃ§Ã£o | GrÃ¡ficos comparativos (Python/matplotlib) |
| **AnÃ¡lise de Cache** | **Script para comparaÃ§Ã£o FIFO vs LRU com grÃ¡ficos** |

---

## Como Compilar e Executar

### InstalaÃ§Ã£o RÃ¡pida (3 passos)

```bash
# Clone o repositÃ³rio
git clone https://github.com/Jottynha/SO-SimuladorVonNeumann.git
cd SO-SimuladorVonNeumann

# Configure e compile (cria build/, executa cmake e compila tudo)
make

# Execute o simulador
make run
```


---

### Comandos DisponÃ­veis

Execute `make help` para ver todos os comandos:

| Comando | DescriÃ§Ã£o |
|---------|-----------|
| **ConfiguraÃ§Ã£o e Build** ||
| `make` | Configura e compila o projeto completo (setup + build) |
| `make setup` | Cria diretÃ³rio `build/` e executa `cmake` |
| `make build` | Compila o simulador e testes |
| `make install-deps` | Instala dependÃªncias Python (matplotlib, pandas, etc.) |
| **ExecuÃ§Ã£o** ||
| `make run` | Executa o simulador principal |
| `make test` | Executa todos os testes |
| `make check` | VerificaÃ§Ã£o rÃ¡pida (PASSOU/FALHOU) |
| **AnÃ¡lise** ||
| `make plots` | Gera grÃ¡ficos de anÃ¡lise de desempenho |
| `make plots-extended` | AnÃ¡lise estendida (degradaÃ§Ã£o, speedup) |
| **Limpeza** ||
| `make clean` | Remove todo o diretÃ³rio `build/` |
| `make clean-results` | Remove apenas resultados (.dat, .csv, .png) |
| **Ajuda** ||
| `make help` | Mostra lista completa de comandos |

---

### Executando o Simulador

#### Modo Interativo (Recomendado)

```bash
make run
```

VocÃª verÃ¡ o menu interativo:

```
=== SIMULADOR DE ARQUITETURA MULTICORE VON NEUMANN ===

Digite o nÃºmero de cores (1-8): 4
ConfiguraÃ§Ã£o: 4 core(s)
Usar multi-threading? (s/n, padrÃ£o: s): s
Threading: HABILITADO (execuÃ§Ã£o paralela)

Escolha o algoritmo de escalonamento:
1. FCFS (First-Come, First-Served)
2. SJN (Shortest Job Next)
3. Priority
4. Round Robin (RR)
5. Executar TODOS e Comparar
Digite sua escolha (1-5): 5

Executando FCFS...
Executando SJN...
Executando Priority...
Executando RoundRobin...

ğŸ“Š MÃ©tricas salvas em: build/output/
```

#### Modo Linha de Comando

O simulador suporta **argumentos de linha de comando** para automaÃ§Ã£o:

**Sintaxe:**
```bash
./build/simulador [opÃ§Ãµes]
```

**OpÃ§Ãµes disponÃ­veis:**

| OpÃ§Ã£o | ParÃ¢metros | DescriÃ§Ã£o | PadrÃ£o |
|-------|------------|-----------|--------|
| `--cores` | `<n>` | NÃºmero de cores (1-8) | 1 |
| `--scheduler` | `FCFS\|SJN\|Priority\|RR` | Algoritmo de escalonamento | FCFS |
| `--replacement` | `FIFO\|LRU` | PolÃ­tica de substituiÃ§Ã£o de cache | FIFO |
| `--quantum` | `<n>` | Quantum para Round Robin (ciclos) | 5 |
| `--no-threads` | - | Desabilita multi-threading | Threading habilitado |
| `--config` | `<dir>` | DiretÃ³rio dos arquivos de processos | `processes/` |
| `--tasks` | `<dir>` | DiretÃ³rio dos arquivos de tarefas | `tasks/` |
| `--output` | `<dir>` | DiretÃ³rio de saÃ­da | `output/` |
| `--help` | - | Mostra ajuda | - |

**Exemplos de uso:**

```bash
# 1. Executar com 4 cores, Round Robin e LRU
./build/simulador --cores 4 --scheduler RR --replacement LRU

# 2. Single-core com FIFO (baseline)
./build/simulador --cores 1 --replacement FIFO

# 3. Multicore sem threads (sequencial)
./build/simulador --cores 4 --no-threads

# 4. ConfiguraÃ§Ã£o completa customizada
./build/simulador \
    --cores 8 \
    --scheduler Priority \
    --replacement LRU \
    --config custom_processes/ \
    --tasks custom_tasks/ \
    --output results/
```

---

### Testando PolÃ­ticas de Cache (FIFO vs LRU)

O projeto inclui um **script automatizado** para testar e comparar as polÃ­ticas FIFO e LRU em diferentes cenÃ¡rios.

#### MÃ©todo 1: Script Automatizado (Recomendado)

**1. Execute o script de teste:**

```bash
bash scripts/test_cache_policies.sh
```

**O que o script faz:**

1. **Executa 4 simulaÃ§Ãµes:**
   - FIFO com 1 core (single-core)
   - LRU com 1 core (single-core)
   - FIFO com 8 cores (multi-core)
   - LRU com 8 cores (multi-core)

2. **Coleta mÃ©tricas:**
   - Tempo de execuÃ§Ã£o (ms)
   - Taxa de cache hit (%)
   - Cache hits e misses
   - Throughput (processos/s)
   - Context switches

3. **Gera comparaÃ§Ãµes:**
   - Tabela comparativa no terminal
   - AnÃ¡lise de melhoria percentual
   - Arquivos CSV em `build/output/*/`

**SaÃ­da esperada:**

```
========================================
  TESTE DE POLÃTICAS DE CACHE
  FIFO vs LRU
========================================

========== TESTE 1: Single-Core (1 core) ==========

[1/4] Executando FIFO com 1 core...
      ConcluÃ­do! Resultados em build/output/fifo_1core/
[2/4] Executando LRU com 1 core...
      ConcluÃ­do! Resultados em build/output/lru_1core/

========== TESTE 2: Multi-Core (8 cores) ==========

[3/4] Executando FIFO com 8 cores...
      ConcluÃ­do! Resultados em build/output/fifo_8cores/
[4/4] Executando LRU com 8 cores...
      ConcluÃ­do! Resultados em build/output/lru_8cores/

========== ANÃLISE DOS RESULTADOS ==========

Single-Core (1 core):
FIFO                 29.24 ms | Hit:  19.93% | Throughput: 307.85 | CPU:  19.21%
LRU                  25.88 ms | Hit:  21.13% | Throughput: 347.79 | CPU:  19.21%

Multi-Core (8 cores):
FIFO                 28.25 ms | Hit:  19.44% | Throughput: 318.60 | CPU:  19.21%
LRU                  26.98 ms | Hit:  21.99% | Throughput: 333.53 | CPU:  19.21%

========== COMPARAÃ‡ÃƒO DETALHADA ==========

Single-Core (1 core):
  Cache Hit Rate:
    FIFO: 19.93%
    LRU:  21.13%
    â†’ LRU Ã© 1.20% melhor
  Tempo de ExecuÃ§Ã£o:
    FIFO: 29.235 ms
    LRU:  25.878 ms
    â†’ LRU Ã© 11.00% mais rÃ¡pido

Multi-Core (8 cores):
  Cache Hit Rate:
    FIFO: 19.44%
    LRU:  21.99%
    â†’ LRU Ã© 2.55% melhor
  Tempo de ExecuÃ§Ã£o:
    FIFO: 28.249 ms
    LRU:  26.984 ms
    â†’ LRU Ã© 4.00% mais rÃ¡pido
```

**2. Gere grÃ¡ficos comparativos:**

```bash
python3 scripts/compare_cache_results.py
```

**GrÃ¡ficos gerados:**

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `build/plots/cache_comparison_fifo_vs_lru.png` | ComparaÃ§Ã£o completa com 4 subgrÃ¡ficos:<br>â€¢ Cache Hit Rate (%)<br>â€¢ Tempo de ExecuÃ§Ã£o (ms)<br>â€¢ Throughput (processos/s)<br>â€¢ Ganho de Desempenho (LRU vs FIFO) |
| `build/plots/cache_comparison_normalized.png` | ComparaÃ§Ã£o normalizada de todas as mÃ©tricas<br>VisualizaÃ§Ã£o lado a lado: 1 core vs 8 cores |

**Exemplo de anÃ¡lise gerada:**

```
====================================================================================================
  COMPARAÃ‡ÃƒO FIFO vs LRU
====================================================================================================

Single-Core (1 core):
----------------------------------------------------------------------------------------------------
PolÃ­tica     Tempo (ms)   Hit Rate (%)       Hits     Misses   Throughput   Ctx Switch
----------------------------------------------------------------------------------------------------
FIFO             29.235          19.93        179          -       307.85            0
LRU              25.878          21.13        190          -       347.79            0

  Melhoria LRU vs FIFO:
    Hit Rate: +1.20% (+melhor)
    Tempo:    +11.48% (+mais rÃ¡pido)

Multi-Core (8 cores):
----------------------------------------------------------------------------------------------------
PolÃ­tica     Tempo (ms)   Hit Rate (%)       Hits     Misses   Throughput   Ctx Switch
----------------------------------------------------------------------------------------------------
FIFO             28.249          19.44        174          -       318.60            0
LRU              26.984          21.99        197          -       333.53            0

  Melhoria LRU vs FIFO:
    Hit Rate: +2.55% (+melhor)
    Tempo:    +4.48% (+mais rÃ¡pido)

ANÃLISE GERAL:
    LRU Ã© melhor em ambos os cenÃ¡rios (single e multi-core)
     Ganho mÃ©dio de hit rate: 1.87%

  ConclusÃµes:
    â€¢ LRU tem maior vantagem em ambiente multi-core
    â€¢ Cache pollution Ã© melhor tratada por LRU
```

#### MÃ©todo 2: ExecuÃ§Ã£o Manual

Se preferir testar manualmente cada polÃ­tica:

**1. Teste FIFO com 1 core:**

```bash
cd build
./simulador --cores 1 --replacement FIFO --scheduler FCFS --output output/fifo_1core
```

**2. Teste LRU com 1 core:**

```bash
./simulador --cores 1 --replacement LRU --scheduler FCFS --output output/lru_1core
```

**3. Teste FIFO com 8 cores:**

```bash
./simulador --cores 8 --replacement FIFO --scheduler FCFS --output output/fifo_8cores
```

**4. Teste LRU com 8 cores:**

```bash
./simulador --cores 8 --replacement LRU --scheduler FCFS --output output/lru_8cores
```

**5. Compare os resultados:**

```bash
# Visualize os CSVs gerados
cat output/fifo_1core/metrics_single.csv
cat output/lru_1core/metrics_single.csv

# Ou use o script de comparaÃ§Ã£o
python3 ../scripts/compare_cache_results.py
```

#### Arquivos Gerados pelos Testes de Cache

ApÃ³s executar os testes, vocÃª encontrarÃ¡:

```
build/output/
â”œâ”€â”€ fifo_1core/
â”‚   â”œâ”€â”€ metrics_single.csv           # MÃ©tricas FIFO 1 core
â”‚   â”œâ”€â”€ resultados_FCFS.dat          # Log detalhado
â”‚   â””â”€â”€ log.txt                      # Output do simulador
â”œâ”€â”€ lru_1core/
â”‚   â”œâ”€â”€ metrics_single.csv           # MÃ©tricas LRU 1 core
â”‚   â”œâ”€â”€ resultados_FCFS.dat
â”‚   â””â”€â”€ log.txt
â”œâ”€â”€ fifo_8cores/
â”‚   â”œâ”€â”€ metrics_multi.csv            # MÃ©tricas FIFO 8 cores
â”‚   â”œâ”€â”€ resultados_FCFS_multicore.dat
â”‚   â””â”€â”€ log.txt
â””â”€â”€ lru_8cores/
    â”œâ”€â”€ metrics_multi.csv            # MÃ©tricas LRU 8 cores
    â”œâ”€â”€ resultados_FCFS_multicore.dat
    â””â”€â”€ log.txt

build/plots/
â”œâ”€â”€ cache_comparison_fifo_vs_lru.png      # GrÃ¡fico comparativo principal
â””â”€â”€ cache_comparison_normalized.png        # ComparaÃ§Ã£o normalizada
```

---

### Resultados Esperados (FIFO vs LRU)

Com base nos testes realizados, espera-se observar:

| MÃ©trica | FIFO | LRU | Vantagem LRU |
|---------|------|-----|--------------|
| **Cache Hit Rate (1 core)** | ~20% | ~21% | +1.2% |
| **Cache Hit Rate (8 cores)** | ~19% | ~22% | +2.5% |
| **Tempo de ExecuÃ§Ã£o (1 core)** | ~29ms | ~26ms | 11% mais rÃ¡pido |
| **Tempo de ExecuÃ§Ã£o (8 cores)** | ~28ms | ~27ms | 4% mais rÃ¡pido |
| **Throughput (1 core)** | ~308 p/s | ~348 p/s | +13% |
| **Throughput (8 cores)** | ~319 p/s | ~334 p/s | +5% |

**ConclusÃµes:**

1. **LRU Ã© superior ao FIFO** em todos os cenÃ¡rios testados
2. **Maior ganho em multi-core**: LRU trata melhor cache pollution
3. **ReduÃ§Ã£o de tempo**: AtÃ© 11% mais rÃ¡pido em single-core
4. **Hit rate**: Consistentemente 1-2.5% melhor
5. **Throughput**: AtÃ© 13% mais processos completados por segundo

---

### Arquitetura Von Neumann Multicore

#### Pipeline MIPS de 5 EstÃ¡gios
O simulador implementa um pipeline completo conforme arquitetura MIPS:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FETCH  â”‚ -> â”‚ DECODE â”‚ -> â”‚EXECUTE â”‚ -> â”‚ MEMORY â”‚ -> â”‚WRITEBACKâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   IF            ID             EX            MEM            WB
```

**EstÃ¡gios:**
1. **Fetch (IF)**: Busca instruÃ§Ã£o da memÃ³ria usando PC (Program Counter)
2. **Decode (ID)**: Decodifica instruÃ§Ã£o e lÃª registradores
3. **Execute (EX)**: Executa operaÃ§Ã£o aritmÃ©tica/lÃ³gica na ULA
4. **Memory (MEM)**: Acessa memÃ³ria para load/store
5. **WriteBack (WB)**: Escreve resultado no banco de registradores

#### ConfiguraÃ§Ã£o Multicore
- **Cores**: 1 a 8 nÃºcleos configurÃ¡veis pelo usuÃ¡rio
- **Threads**: Cada core executa em thread C++ separada
- **SincronizaÃ§Ã£o**: Mutexes para acesso Ã  memÃ³ria compartilhada
- **MÃ©tricas**: UtilizaÃ§Ã£o individual por core

**CaracterÃ­sticas:**
- MemÃ³ria principal unificada e compartilhada
- Escalonamento distribuÃ­do entre cores
- SincronizaÃ§Ã£o sem condiÃ§Ã£o de corrida
- AnÃ¡lise de speedup multicore vs single-core

### PolÃ­ticas de Escalonamento

Conforme especificado no enunciado, o simulador implementa **4 polÃ­ticas de escalonamento** com suporte a cenÃ¡rios preemptivos e nÃ£o-preemptivos:

| PolÃ­tica | Tipo | DescriÃ§Ã£o | CenÃ¡rio |
|----------|------|-----------|---------|
| **FCFS** | NÃ£o-preemptivo | First-Come, First-Served - ordem de chegada | Executa atÃ© conclusÃ£o |
| **SJN** | NÃ£o-preemptivo | Shortest Job Next - menor tempo estimado primeiro | Executa atÃ© conclusÃ£o |
| **Priority** | NÃ£o-preemptivo | Baseado em prioridades (1-5), maior prioridade primeiro | Executa atÃ© conclusÃ£o |
| **Round Robin** | **Preemptivo** | Quantum de tempo (5 ciclos) com rodÃ­zio circular | **InterruptÃ­vel por quantum** |

#### CenÃ¡rio NÃ£o-Preemptivo (FCFS, SJN, Priority)
- Processos executam **atÃ© a conclusÃ£o** sem interrupÃ§Ãµes
- Ordem determinada pelo escalonador no inÃ­cio
- Ideal para demonstrar diferentes estratÃ©gias de ordenaÃ§Ã£o

#### CenÃ¡rio Preemptivo (Round Robin)
- Processos **interruptÃ­veis** apÃ³s quantum (5 ciclos de pipeline)
- **Context switch** automÃ¡tico ao expirar quantum
- Estado do processo salvo (PC, registradores, mÃ©tricas)
- RecolocaÃ§Ã£o na fila Ready para retomada posterior
- **SimulaÃ§Ã£o de cache pollution** durante troca de contexto

**ImplementaÃ§Ã£o de PreempÃ§Ã£o:**
```cpp
// CONTROL_UNIT.cpp - linha 469
if (clock >= process.quantum) {
    context.endExecution = true;  // Marca para preempÃ§Ã£o
}

// main.cpp - linha 350-357
if (current_process->state == State::Ready) {
    // Processo nÃ£o terminou, recoloca na fila
    scheduler.add_process(current_process);
    memManager.simulateContextSwitch(); // Cache pollution
    scheduler.increment_context_switch();
}
```

### Gerenciamento de MemÃ³ria (Modelo Tanenbaum)

O simulador implementa um sistema completo de gerenciamento de memÃ³ria conforme especificado no enunciado, baseado no modelo de Tanenbaum.

#### Hierarquia de MemÃ³ria (3 NÃ­veis)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CPU CORES                         â”‚
â”‚                 (1-8 nÃºcleos)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚  Cache L1   â”‚  â—„â”€â”€ FIFO ou LRU
              â”‚  256 blocos â”‚      (substituiÃ§Ã£o)
              â”‚   4 bytes   â”‚
              â”‚   = 1 KB    â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ miss
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚  RAM        â”‚  â—„â”€â”€ MemÃ³ria principal
              â”‚ 4096 blocos â”‚      compartilhada
              â”‚  4 bytes    â”‚
              â”‚  = 16 KB    â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ swap
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ Disco/Swap  â”‚  â—„â”€â”€ MemÃ³ria secundÃ¡ria
              â”‚  Ilimitado  â”‚      (virtual)
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**EspecificaÃ§Ãµes:**
- **Cache L1**: 256 blocos Ã— 4 bytes = 1 KB (por core)
- **RAM**: 4096 blocos Ã— 4 bytes = 16 KB (compartilhada)
- **Swap**: Capacidade ilimitada (simulaÃ§Ã£o de disco)

**LatÃªncias:**
- Cache hit: 1 ciclo
- RAM: 5 ciclos
- Swap: 10 ciclos

#### SegmentaÃ§Ã£o de MemÃ³ria (Modelo Tanenbaum)

ImplementaÃ§Ã£o completa do modelo de segmentaÃ§Ã£o conforme Tanenbaum, com 4 segmentos:

| Segmento | ID BinÃ¡rio | DescriÃ§Ã£o | Base | Limite | ProteÃ§Ã£o |
|----------|------------|-----------|------|--------|----------|
| **CODE** | `00` | CÃ³digo do programa (instruÃ§Ãµes) | DinÃ¢mico | Por processo | **Read-Only** |
| **DATA** | `01` | VariÃ¡veis globais e estÃ¡ticas | DinÃ¢mico | Por processo | Read-Write |
| **STACK** | `10` | Pilha de execuÃ§Ã£o (chamadas) | DinÃ¢mico | Por processo | Read-Write |
| **HEAP** | `11` | AlocaÃ§Ã£o dinÃ¢mica de memÃ³ria | DinÃ¢mico | Por processo | Read-Write |

**Formato de EndereÃ§o LÃ³gico (32 bits):**
```
 31  30 | 29                                    0
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Seg ID â”‚           Offset                     â”‚
â”‚2 bits  â”‚          30 bits                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Exemplos:
0x00000064 = 00|000064 â†’ CODE, offset 100 (instruÃ§Ã£o no endereÃ§o 100)
0x40000100 = 01|000100 â†’ DATA, offset 256 (variÃ¡vel global)
0x80000050 = 10|000050 â†’ STACK, offset 80 (frame de funÃ§Ã£o)
0xC0000200 = 11|000200 â†’ HEAP, offset 512 (malloc)
```

**TraduÃ§Ã£o de EndereÃ§o:**
```
EndereÃ§o LÃ³gico â†’ [Tabela de Segmentos] â†’ EndereÃ§o FÃ­sico

1. Extrair Segmento (bits 31-30)
2. Extrair Offset (bits 29-0)
3. Verificar limites: offset < segment.limit
4. Verificar proteÃ§Ã£o: read-only vs read-write
5. Calcular fÃ­sico: segment.base + offset
```

**ImplementaÃ§Ã£o (`src/memory/SegmentTable.hpp`):**
```cpp
class SegmentTable {
    struct Segment {
        uint32_t base;      // EndereÃ§o base fÃ­sico
        uint32_t limit;     // Tamanho do segmento
        bool present;       // Segmento carregado?
        bool read_only;     // ProteÃ§Ã£o de escrita
    };
    
    Segment segments[4];  // CODE, DATA, STACK, HEAP
    
    uint32_t translate(uint8_t segment_id, uint32_t offset);
    bool checkProtection(uint8_t segment_id, bool is_write);
};

class SegmentedAddressing {
    // Codificar: segmento + offset â†’ endereÃ§o lÃ³gico 32 bits
    uint32_t encodeAddress(uint8_t segment_id, uint32_t offset);
    
    // Decodificar: endereÃ§o lÃ³gico â†’ (segmento, offset)
    std::pair<uint8_t, uint32_t> decodeAddress(uint32_t logical_addr);
};
```

#### PolÃ­ticas de SubstituiÃ§Ã£o de Cache

O simulador implementa **duas polÃ­ticas** de substituiÃ§Ã£o de blocos na cache, conforme especificado:

##### 1. FIFO (First In, First Out)
- Substitui o **bloco mais antigo** (primeiro a entrar)
- Simples e previsÃ­vel
- NÃ£o considera padrÃ£o de acesso

##### 2. LRU (Least Recently Used) 
- Substitui o **bloco menos recentemente usado**
- MantÃ©m blocos "quentes" (frequentemente acessados)
- ImplementaÃ§Ã£o com lista ordenada de acesso

**ImplementaÃ§Ã£o (`src/memory/cachePolicy.hpp`):**
```cpp
enum class ReplacementPolicy {
    FIFO,  // First In, First Out
    LRU    // Least Recently Used (implementado)
};

class CachePolicy {
    // FIFO: retorna endereÃ§o mais antigo
    size_t getAddressToReplace();
    
    // LRU: retorna endereÃ§o menos recentemente usado
    size_t getAddressToReplaceLRU(std::list<size_t>& lru_list);
    
    // Atualiza lista LRU apÃ³s acesso
    void updateLRU(std::list<size_t>& lru_list, size_t address);
};

class Cache {
    ReplacementPolicy policy;     // FIFO ou LRU
    std::list<size_t> lru_list;   // Lista de acesso para LRU
    
    // Alternar polÃ­tica dinamicamente
    void setPolicy(ReplacementPolicy new_policy);
};
```

**ComparaÃ§Ã£o:**
| MÃ©trica | FIFO | LRU |
|---------|------|-----|
| Complexidade | O(1) | O(n) |
| Taxa de Hit | ~13% | ~13-15% |
| Overhead | Baixo | MÃ©dio |
| Uso | Baseline | ProduÃ§Ã£o |

#### Rastreamento Temporal de MemÃ³ria

Conforme requisito do enunciado: **"utilizaÃ§Ã£o de memÃ³ria ao longo do tempo"**

**Snapshots AutomÃ¡ticos:**
- Capturados **a cada 10 ciclos de pipeline**
- Snapshot inicial (ciclo 0)
- Snapshots periÃ³dicos durante execuÃ§Ã£o
- Snapshot final (tÃ©rmino do processo)

**Estrutura de Snapshot (`src/cpu/PCB.hpp`):**
```cpp
struct MemorySnapshot {
    int64_t timestamp_ms;      // Momento da captura
    uint64_t cache_usage;      // Bytes usados na cache
    uint64_t ram_usage;        // Bytes usados na RAM
    uint64_t total_accesses;   // Total de acessos atÃ© agora
    double cache_hit_rate;     // Taxa de hit (%)
};

struct PCB {
    // ... outros campos
    std::vector<MemorySnapshot> memory_usage_timeline;
};
```

**ImplementaÃ§Ã£o (`src/memory/MemoryUsageTracker.hpp`):**
```cpp
class MemoryUsageTracker {
public:
    // Captura snapshot do processo
    static void recordSnapshot(PCB& process, 
                              uint64_t cache_usage, 
                              uint64_t ram_usage);
    
    // Gera relatÃ³rio individual do processo
    static void generateReport(const PCB& process, 
                              const std::string& output_dir);
    
    // Gera relatÃ³rio agregado de todos os processos
    static void generateAggregatedReport(
        const std::vector<std::unique_ptr<PCB>>& processes,
        const std::string& output_file);
};
```

**IntegraÃ§Ã£o no Pipeline (`src/cpu/CONTROL_UNIT.cpp`):**
```cpp
void* Core(MemoryManager& memManager, PCB& process, ...) {
    const int SNAPSHOT_INTERVAL = 10;
    int snapshot_counter = 0;
    
    // Snapshot inicial
    MemoryUsageTracker::recordSnapshot(process, 0, 0);
    
    while (context.counterForEnd > 0) {
        // ... execuÃ§Ã£o do pipeline
        
        snapshot_counter++;
        if (snapshot_counter >= SNAPSHOT_INTERVAL) {
            uint64_t cache_usage = (process.cache_hits + process.cache_misses) * 4;
            uint64_t ram_usage = process.primary_mem_accesses * 4;
            MemoryUsageTracker::recordSnapshot(process, cache_usage, ram_usage);
            snapshot_counter = 0;
        }
    }
    
    // Snapshot final
    MemoryUsageTracker::recordSnapshot(process, final_cache, final_ram);
}
```

**RelatÃ³rios Gerados:**

1. **Individuais** (9 arquivos): `memory_usage_<nome>_<pid>.txt`
```
========================================
  RELATORIO DE UTILIZACAO DE MEMORIA  
  Processo: Quick Process (PID: 1)
========================================

Tempo(ms)      Cache(bytes)     RAM(bytes)    Total Acess      Cache Hit(%)
---------------------------------------------------------------------------
1700000001              0              0              0              0.00
1700000015            128             40             10             20.00
1700000029            256             40             15             26.67

=== ESTATISTICAS FINAIS ===
Total de snapshots: 3
Memoria cache maxima: 256 bytes
Memoria RAM maxima: 40 bytes
Taxa de cache final: 26.67%
```

2. **Agregado**: `memory_aggregated_report.txt`
```
========================================
RELATORIO AGREGADO DE UTILIZACAO DE MEMORIA
========================================

Total de processos: 9
Periodo de analise: 1700000001 a 1700000150

=== ESTATISTICAS GLOBAIS ===
Cache maxima utilizada: 504 bytes
RAM maxima utilizada: 360 bytes
Taxa de cache hit media: 13.16%

=== RESUMO POR PROCESSO ===
PID  Nome                    Cache Max  RAM Max  Hit Rate
----------------------------------------------------------------
1    Quick Process              128        40      20.00%
2    Short Process              256        80      25.00%
...
9    Loop-Heavy Process         504       360       5.49%
```

### MÃ©tricas de Desempenho

Conforme especificado no enunciado do trabalho, o simulador coleta e reporta **todas as mÃ©tricas** necessÃ¡rias para anÃ¡lise comparativa entre polÃ­ticas de escalonamento:

#### MÃ©tricas de Tempo (por processo)
- **Tempo de Espera** (Wait Time): `start_time - arrival_time`
- **Tempo de Resposta** (Response Time): `start_time - arrival_time`
- **Tempo de Retorno** (Turnaround Time): `finish_time - arrival_time`

#### MÃ©tricas de Sistema (agregadas)
- **UtilizaÃ§Ã£o MÃ©dia da CPU**: Percentual de tempo de CPU ocupado
- **EficiÃªncia por NÃºcleo**: UtilizaÃ§Ã£o individual de cada core (multicore)
- **Throughput**: Processos completados por segundo
- **Context Switches**: NÃºmero de trocas de contexto (preempÃ§Ã£o)

#### MÃ©tricas de MemÃ³ria
- **Taxa de Cache Hit**: `(hits / total_accesses) * 100`
- **Ciclos de MemÃ³ria**: Tempo gasto em acessos Ã  hierarquia
- **Acessos por NÃ­vel**: Cache L1, RAM, Swap
- **UtilizaÃ§Ã£o Temporal**: EvoluÃ§Ã£o do uso de memÃ³ria ao longo do tempo

#### Exemplo de RelatÃ³rio

```
--- METRICAS FINAIS DO PROCESSO 1 ---
Nome do Processo:       Quick Process
Estado Final:           Finished
Prioridade:             1
Quantum:                5

--- METRICAS DE TEMPO ---
Tempo de Espera:        0 ms
Tempo de Resposta:      0 ms
Tempo de Retorno:       12 ms

--- METRICAS DE CPU E MEMORIA ---
Ciclos de Pipeline:     9
Total de Acessos a Mem: 15
  - Leituras:             10
  - Escritas:             5
Acessos a Cache L1:     5
Acessos a Mem Principal:10
Acessos a Mem Secundaria:0
Ciclos Totais de Memoria: 55
Cache Hits:             3
Cache Misses:           12
Ciclos de IO:           1

--- UTILIZACAO DE MEMORIA ---
Snapshots registrados:  2
Taxa de cache final:    20.00%
```

### Processos de Teste (Lote Inicial)

Conforme especificaÃ§Ã£o do enunciado: **"Ler do disco um lote inicial de programas previamente definido. NÃ£o Ã© permitida chegada de novos processos durante a execuÃ§Ã£o."**

O simulador carrega **9 processos** do disco antes de iniciar a execuÃ§Ã£o. Nenhum processo novo Ã© criado durante a simulaÃ§Ã£o.

| Processo | PID | Arquivo JSON | DescriÃ§Ã£o | InstruÃ§Ãµes | Prioridade |
|----------|-----|--------------|-----------|------------|------------|
| Quick | 1 | `process_quick.json` | Processo rÃ¡pido (baseline) | 5 | 1 (alta) |
| Short | 2 | `process_short.json` | Processo curto | 5 | 2 |
| Medium | 3 | `process_medium.json` | Processo mÃ©dio | 5 | 2 |
| Long | 4 | `process_long.json` | Processo longo | 5 | 1 (alta) |
| CPU-Bound | 5 | `process_cpu_bound.json` | Uso intensivo de CPU | 5 | 3 (baixa) |
| IO-Bound | 6 | `process_io_bound.json` | Muitas requisiÃ§Ãµes I/O | 5 | 1 (alta) |
| Memory-Intensive | 7 | `process_memory_intensive.json` | Muitos acessos Ã  memÃ³ria | 5 | 2 |
| Balanced | 8 | `process_balanced.json` | Carga balanceada | 5 | 2 |
| Loop-Heavy | 9 | `process_loop_heavy.json` | Loop intenso (preempÃ§Ã£o) | **100** | 2 |

**CaracterÃ­sticas dos Processos:**

1. **Quick/Short/Medium/Long**: Processos baseline com diferentes tempos esperados
2. **CPU-Bound**: Muitas operaÃ§Ãµes aritmÃ©ticas (ADD, SUB, MUL)
3. **IO-Bound**: Muitas instruÃ§Ãµes PRINT (requisiÃ§Ãµes de I/O)
4. **Memory-Intensive**: Muitas instruÃ§Ãµes LOAD/STORE
5. **Balanced**: Mix equilibrado de operaÃ§Ãµes
6. **Loop-Heavy**: 100 instruÃ§Ãµes ADD para demonstrar preempÃ§Ã£o no Round Robin

**Estrutura dos Arquivos:**

`processes/process_*.json` (configuraÃ§Ã£o do PCB):
```json
{
  "pid": 1,
  "name": "Quick Process",
  "priority": 1,
  "quantum": 5,
  "arrival_time": 0
}
```

`tasks/tasks_*.json` (programa MIPS):
```json
{
  "program": [
    { "instruction": "li", "rt": "$t0", "immediate": 10 },
    { "instruction": "li", "rt": "$t1", "immediate": 20 },
    { "instruction": "add", "rd": "$t2", "rs": "$t0", "rt": "$t1" },
    { "instruction": "print", "rt": "$t2" },
    { "instruction": "end" }
  ]
}
```

**Carregamento (em `src/main.cpp`):**
```cpp
void load_processes(std::vector<std::unique_ptr<PCB>>& process_list,
                    MemoryManager& memManager) {
    // Carrega TODOS os 9 processos antes de iniciar
    for (int i = 1; i <= 9; i++) {
        auto process = std::make_unique<PCB>();
        load_pcb_from_json($"process_{name}.json", *process);
        loadJsonProgram($"tasks_{name}.json", memManager, *process, base_addr);
        process_list.push_back(std::move(process));
    }
    // Nenhum processo novo Ã© criado apÃ³s este ponto
}
```

---

## Estrutura do Projeto

```
SO-SimuladorVonNeumann/
â”œâ”€â”€ CMakeLists.txt                    # Build system principal
â”œâ”€â”€ Makefile                          # Wrapper para comandos comuns
â”œâ”€â”€ README.md                         # Este documento
â”œâ”€â”€ RESUMO_MUDANÃ‡AS.md               # Log de alteraÃ§Ãµes
â”œâ”€â”€ LICENSE                           # LicenÃ§a MIT
â”œâ”€â”€ enunciado.pdf                     # EspecificaÃ§Ã£o do trabalho
â”‚
â”œâ”€â”€ src/                              # CÃ³digo-fonte C++
â”‚   â”œâ”€â”€ main.cpp                      # Ponto de entrada principal
â”‚   â”œâ”€â”€ cpu/                          # Componentes da CPU
â”‚   â”‚   â”œâ”€â”€ CONTROL_UNIT.cpp/.hpp     # Unidade de controle (pipeline)
â”‚   â”‚   â”œâ”€â”€ PCB.hpp                   # Process Control Block
â”‚   â”‚   â”œâ”€â”€ REGISTER_BANK.cpp/.hpp    # Banco de 32 registradores
â”‚   â”‚   â”œâ”€â”€ REGISTER.cpp/.hpp         # Registrador individual
â”‚   â”‚   â”œâ”€â”€ HASH_REGISTER.hpp         # Mapa de nomes $t0 â†’ Ã­ndice
â”‚   â”‚   â”œâ”€â”€ ULA.cpp/.hpp              # Unidade LÃ³gica AritmÃ©tica
â”‚   â”‚   â”œâ”€â”€ FETCH.cpp/.hpp            # EstÃ¡gio Fetch (IF)
â”‚   â”‚   â”œâ”€â”€ DECODE.cpp/.hpp           # EstÃ¡gio Decode (ID)
â”‚   â”‚   â”œâ”€â”€ EXECUTE.cpp/.hpp          # EstÃ¡gio Execute (EX)
â”‚   â”‚   â”œâ”€â”€ MEMORY_ACCESS.cpp/.hpp    # EstÃ¡gio Memory (MEM)
â”‚   â”‚   â”œâ”€â”€ WRITE_BACK.cpp/.hpp       # EstÃ¡gio WriteBack (WB)
â”‚   â”‚   â”œâ”€â”€ Scheduler.cpp/.hpp        # Escalonador (4 polÃ­ticas)
â”‚   â”‚   â””â”€â”€ CPUMetrics.cpp/.hpp       # MÃ©tricas de desempenho
â”‚   â”œâ”€â”€ memory/                       # Gerenciamento de memÃ³ria
â”‚   â”‚   â”œâ”€â”€ MemoryManager.cpp/.hpp    # Gerenciador central
â”‚   â”‚   â”œâ”€â”€ Cache.cpp/.hpp            # Cache L1 (FIFO/LRU)
â”‚   â”‚   â”œâ”€â”€ cachePolicy.cpp/.hpp      # PolÃ­ticas de substituiÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ SegmentTable.hpp          # Tabela de segmentos
â”‚   â”‚   â”œâ”€â”€ SegmentedAddressing.hpp   # CodificaÃ§Ã£o de endereÃ§os
â”‚   â”‚   â””â”€â”€ MemoryUsageTracker.hpp    # Rastreamento temporal
â”‚   â”œâ”€â”€ IO/                           # Sistema de I/O
â”‚   â”‚   â””â”€â”€ Disk.cpp/.hpp             # SimulaÃ§Ã£o de disco
â”‚   â””â”€â”€ parser_json/                  # Leitor de JSON
â”‚       â””â”€â”€ JsonParser.cpp/.hpp       # Parsing de configuraÃ§Ãµes
â”‚
â”œâ”€â”€ processes/                        # ConfiguraÃ§Ãµes PCB (JSON)
â”‚   â”œâ”€â”€ process_quick.json            # Processo 1
â”‚   â”œâ”€â”€ process_short.json            # Processo 2
â”‚   â”œâ”€â”€ process_medium.json           # Processo 3
â”‚   â”œâ”€â”€ process_long.json             # Processo 4
â”‚   â”œâ”€â”€ process_cpu_bound.json        # Processo 5
â”‚   â”œâ”€â”€ process_io_bound.json         # Processo 6
â”‚   â”œâ”€â”€ process_memory_intensive.json # Processo 7
â”‚   â”œâ”€â”€ process_balanced.json         # Processo 8
â”‚   â””â”€â”€ process_loop_heavy.json       # Processo 9
â”‚
â”œâ”€â”€ tasks/                            # Programas MIPS (JSON)
â”‚   â”œâ”€â”€ tasks_quick.json              # 5 instruÃ§Ãµes
â”‚   â”œâ”€â”€ tasks_short.json              # 5 instruÃ§Ãµes
â”‚   â”œâ”€â”€ tasks_medium.json             # 5 instruÃ§Ãµes
â”‚   â”œâ”€â”€ tasks_long.json               # 5 instruÃ§Ãµes
â”‚   â”œâ”€â”€ tasks_cpu_bound.json          # 5 instruÃ§Ãµes (ALU)
â”‚   â”œâ”€â”€ tasks_io_bound.json           # 5 instruÃ§Ãµes (I/O)
â”‚   â”œâ”€â”€ tasks_memory_intensive.json   # 5 instruÃ§Ãµes (MEM)
â”‚   â”œâ”€â”€ tasks_balanced.json           # 5 instruÃ§Ãµes (mix)
â”‚   â””â”€â”€ tasks_loop_heavy.json         # 100 instruÃ§Ãµes (loop)
â”‚
â”œâ”€â”€ scripts/                          # Ferramentas de anÃ¡lise
â”‚   â”œâ”€â”€ compare_schedulers.py         # Compara polÃ­ticas
â”‚   â”œâ”€â”€ plot_memory.py                # GrÃ¡ficos de memÃ³ria
â”‚   â”œâ”€â”€ plot_results.py               # GrÃ¡ficos gerais
â”‚   â”œâ”€â”€ generate_all_plots.sh         # Script mestre
â”‚   â””â”€â”€ requirements.txt              # DependÃªncias Python
â”‚
â”œâ”€â”€ build/                            # DiretÃ³rio de build (gerado)
â”‚   â”œâ”€â”€ simulador                     # ExecutÃ¡vel principal
â”‚   â”œâ”€â”€ test_*                        # ExecutÃ¡veis de teste
â”‚   â”œâ”€â”€ processes/                    # CÃ³pia dos JSONs
â”‚   â”œâ”€â”€ tasks/                        # CÃ³pia dos JSONs
â”‚   â””â”€â”€ output/                       # Resultados gerados
â”‚       â”œâ”€â”€ resultados*.dat           # RelatÃ³rios de escalonamento
â”‚       â”œâ”€â”€ comparacao_escalonadores*.txt # ComparaÃ§Ãµes
â”‚       â”œâ”€â”€ memory_usage_*.txt        # RelatÃ³rios individuais (9)
â”‚       â””â”€â”€ memory_aggregated_report.txt # RelatÃ³rio agregado
â”‚
â””â”€â”€ plots/                            # GrÃ¡ficos gerados (12 arquivos)
    â”œâ”€â”€ scheduler_time_comparison.png
    â”œâ”€â”€ scheduler_efficiency_comparison.png
    â”œâ”€â”€ scheduler_radar_comparison.png
    â”œâ”€â”€ memory_usage_timeline.png
    â”œâ”€â”€ cache_hit_rate_evolution.png
    â”œâ”€â”€ memory_heatmap.png
    â”œâ”€â”€ pipeline_cycles.png
    â”œâ”€â”€ memory_accesses.png
    â”œâ”€â”€ execution_times.png
    â”œâ”€â”€ cache_performance.png
    â”œâ”€â”€ comparison_matrix.png
    â””â”€â”€ memory_final_summary.png
```

---

## DecisÃµes de Projeto e Justificativas

### 1. Arquitetura Multicore Real (C++ Threads)

**DecisÃ£o:** Usar `std::thread` para implementar mÃºltiplos cores.

**Justificativa:**
- ExecuÃ§Ã£o paralela verdadeira (nÃ£o simulada)
- SincronizaÃ§Ã£o com mutexes para memÃ³ria compartilhada
- Demonstra conceitos reais de sistemas operacionais
- Permite anÃ¡lise de speedup real vs single-core

**Alternativas consideradas:**
- SimulaÃ§Ã£o sequencial (nÃ£o demonstraria paralelismo real)
- Processos UNIX (overhead muito alto)

### 2. Pipeline MIPS de 5 EstÃ¡gios

**DecisÃ£o:** Implementar pipeline completo (IF â†’ ID â†’ EX â†’ MEM â†’ WB).

**Justificativa:**
- Conformidade com arquitetura MIPS clÃ¡ssica
- Demonstra conceito de pipeline em CPU real
- Permite anÃ¡lise de ciclos por instruÃ§Ã£o
- Base para extensÃµes futuras (hazards, forwarding)

**Alternativas consideradas:**
- ExecuÃ§Ã£o direta (nÃ£o representaria arquitetura real)
- Pipeline simplificado (perderia detalhes tÃ©cnicos)

### 3. SegmentaÃ§Ã£o (Modelo Tanenbaum)

**DecisÃ£o:** 4 segmentos (CODE, DATA, STACK, HEAP) com proteÃ§Ã£o.

**Justificativa:**
- Modelo clÃ¡ssico de Tanenbaum (livro texto)
- ProteÃ§Ã£o de cÃ³digo (read-only)
- EndereÃ§amento lÃ³gico realista (32 bits)
- Preparado para paginaÃ§Ã£o futura

**Alternativas consideradas:**
- PaginaÃ§Ã£o pura (mais complexo para escopo do trabalho)
- EndereÃ§amento plano (nÃ£o demonstraria conceitos de SO)

### 4. Cache L1 com FIFO e LRU

**DecisÃ£o:** Duas polÃ­ticas de substituiÃ§Ã£o comparÃ¡veis.

**Justificativa:**
- FIFO: baseline simples (O(1))
- LRU: polÃ­tica realista usada em processadores reais
- Permite anÃ¡lise comparativa de desempenho
- Demonstra impacto de polÃ­ticas na taxa de hit

**Alternativas consideradas:**
- Apenas FIFO (nÃ£o mostraria melhorias)
- PolÃ­ticas mais complexas (CLOCK, LFU) - fora do escopo

### 5. Quantum de 5 Ciclos (Round Robin)

**DecisÃ£o:** Quantum fixo de 5 ciclos de pipeline.

**Justificativa:**
- Demonstra preempÃ§Ã£o com processo Loop-Heavy (100 instruÃ§Ãµes)
- Quantum pequeno: maior interatividade
- Permite observar overhead de context switch
- ComparÃ¡vel com sistemas operacionais reais (Linux: 100ms â‰ˆ milhÃµes de ciclos)

**Alternativas consideradas:**
- Quantum de 1 ciclo (overhead excessivo)
- Quantum de 50 ciclos (nÃ£o demonstraria preempÃ§Ã£o)

### 6. Rastreamento Temporal (Snapshots a cada 10 ciclos)

**DecisÃ£o:** Capturar estado de memÃ³ria periodicamente.

**Justificativa:**
- Atende requisito: "utilizaÃ§Ã£o de memÃ³ria ao longo do tempo"
- Intervalo de 10 ciclos: granularidade adequada
- NÃ£o impacta performance (baixo overhead)
- Permite anÃ¡lise temporal e geraÃ§Ã£o de grÃ¡ficos

**Alternativas consideradas:**
- Snapshot a cada ciclo (overhead excessivo, dados redundantes)
- Apenas snapshot final (nÃ£o mostraria evoluÃ§Ã£o temporal)

### 7. JSON para ConfiguraÃ§Ã£o

**DecisÃ£o:** Processos e tarefas definidos em JSON.

**Justificativa:**
- Formato estruturado e legÃ­vel
- FÃ¡cil modificaÃ§Ã£o sem recompilar
- SeparaÃ§Ã£o de cÃ³digo e dados
- Suporte a lote inicial (9 processos)

**Alternativas consideradas:**
- CÃ³digo hardcoded (inflexÃ­vel)
- Entrada manual (nÃ£o reproduzÃ­vel)

### 8. Python para VisualizaÃ§Ã£o

**DecisÃ£o:** Scripts Python com matplotlib para grÃ¡ficos.

**Justificativa:**
- matplotlib: biblioteca padrÃ£o para grÃ¡ficos cientÃ­ficos
- Python: ampla adoÃ§Ã£o em anÃ¡lise de dados
- SeparaÃ§Ã£o de lÃ³gica (C++) e apresentaÃ§Ã£o (Python)
- 12 grÃ¡ficos gerados automaticamente

**Alternativas consideradas:**
- Integrar grÃ¡ficos no C++ (dependÃªncias pesadas)
- Apenas texto (menos visual)

---

## Tecnologias Utilizadas

### Linguagens
- **C++17** - Linguagem principal do simulador
- **Python 3.8+** - Scripts de visualizaÃ§Ã£o
- **Bash** - AutomaÃ§Ã£o de build e testes

### Bibliotecas e Frameworks
- **STL (Standard Template Library)**
  - `<thread>` - Multithreading para multicore
  - `<mutex>` - SincronizaÃ§Ã£o de memÃ³ria compartilhada
  - `<atomic>` - OperaÃ§Ãµes atÃ´micas
  - `<chrono>` - MediÃ§Ã£o de tempo
  - `<vector>`, `<map>`, `<queue>` - Estruturas de dados
  
- **nlohmann/json** - Parsing de arquivos JSON
- **pthread** - Threads POSIX (backend do std::thread)

### Ferramentas Python
- **matplotlib** - GeraÃ§Ã£o de grÃ¡ficos
- **numpy** - CÃ¡lculos numÃ©ricos
- **pandas** (opcional) - AnÃ¡lise de dados

### Build System
- **CMake 3.10+** - ConfiguraÃ§Ã£o de build multiplataforma
- **GNU Make** - Wrapper para comandos comuns
- **GCC 9+ / Clang 10+** - Compiladores C++ com suporte a C++17

### Controle de VersÃ£o
- **Git** - Versionamento de cÃ³digo

### Ambiente de Desenvolvimento
- **Linux Ubuntu 20.04+** - Sistema operacional alvo
- **VS Code / CLion** - IDEs sugeridas
- **GDB** - Debugging
- **Valgrind** - DetecÃ§Ã£o de memory leaks

---

## Equipe de Desenvolvimento

- JoÃ£o Pedro Rodrigues Silva ([jottynha](https://github.com/Jottynha))
- Eduardo da Silva Torres Grillo ([EduardoGrillo](https://github.com/EduardoGrillo))
- Samuel Silva Gomes ([samuelsilvg](https://github.com/samuelsilvg))
- Jader Oliveira Silva ([0livas](https://github.com/0livas))


## ğŸ“„ LicenÃ§a

Este projeto Ã© licenciado sob a **MIT License** - veja o arquivo [LICENSE](LICENSE) para detalhes.

```
MIT License

Copyright (c) 2025 CEFET-MG - Simulador Multicore Von Neumann

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ“š ReferÃªncias BibliogrÃ¡ficas

1. **TANENBAUM, Andrew S.; BOS, Herbert.** *Modern Operating Systems.* 4th ed. Pearson, 2014.
   - CapÃ­tulo 3: Memory Management (Segmentation)
   - CapÃ­tulo 2: Processes and Threads (Scheduling)

2. **PATTERSON, David A.; HENNESSY, John L.** *Computer Organization and Design: The Hardware/Software Interface.* 5th ed. Morgan Kaufmann, 2013.
   - CapÃ­tulo 4: The Processor (MIPS Pipeline)
   - CapÃ­tulo 5: Memory Hierarchy

3. **STALLINGS, William.** *Operating Systems: Internals and Design Principles.* 9th ed. Pearson, 2017.
   - CapÃ­tulo 9: Uniprocessor Scheduling
   - CapÃ­tulo 7: Memory Management

4. **SILBERSCHATZ, Abraham; GALVIN, Peter B.; GAGNE, Greg.** *Operating System Concepts.* 10th ed. Wiley, 2018.
   - CapÃ­tulo 6: CPU Scheduling
   - CapÃ­tulo 9: Virtual Memory

5. **HENNESSY, John L.; PATTERSON, David A.** *Computer Architecture: A Quantitative Approach.* 6th ed. Morgan Kaufmann, 2017.
   - ApÃªndice C: Pipelining

6. **DocumentaÃ§Ã£o nlohmann/json:** https://github.com/nlohmann/json
   - Parsing de JSON em C++

7. **CPPReference - std::thread:** https://en.cppreference.com/w/cpp/thread/thread
   - Multithreading em C++17

8. **Matplotlib Documentation:** https://matplotlib.org/stable/contents.html
   - GeraÃ§Ã£o de grÃ¡ficos cientÃ­ficos

---



