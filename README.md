<p align="center"> 
  <img src="imgs/logo_azul.png" alt="CEFET-MG" width="100px" height="100px">
</p>

<h1 align="center">
üñ•Ô∏è Simulador Multicore Von Neumann
</h1>

<h3 align="center">
Arquitetura Multicore com Pipeline MIPS, Escalonamento e Gerenciamento de Mem√≥ria
</h3>

<div align="center">

![C++](https://img.shields.io/badge/C%2B%2B-17-blue)
![CMake](https://img.shields.io/badge/CMake-3.10+-green)
![Docker](https://img.shields.io/badge/Docker-ready-informational)
![DevContainers](https://img.shields.io/badge/VSCode-Dev%20Containers-23a)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-100%25%20conclu%C3%ADdo-success)

</div>

---

<div align="justify">
<p><strong>Disciplina:</strong> Sistemas Operacionais<br>
<strong>Institui√ß√£o:</strong> Centro Federal de Educa√ß√£o Tecnol√≥gica de Minas Gerais (CEFET-MG) - Campus V Divin√≥polis<br>
<strong>Professor:</strong> Michel Pires da Silva<br>
<strong>Projeto:</strong> Trabalho Final - Simula√ß√£o de Arquitetura Multicore com Gerenciamento de Mem√≥ria e Escalonamento<br>
</div>


---

## üìñ √çndice

- [Sobre o Projeto](#-sobre-o-projeto)
  - [Evolu√ß√£o do Simulador](#-evolu√ß√£o-do-simulador)
  - [Conformidade com o Enunciado](#-conformidade-com-o-enunciado)
  - [Componentes Implementados](#-componentes-implementados)
- [Fundamentos da Arquitetura Von Neumann](#Ô∏è-fundamentos-da-arquitetura-von-neumann)
- [Organiza√ß√£o do C√≥digo-Fonte](#Ô∏è-organiza√ß√£o-do-c√≥digo-fonte)
- [Componentes da CPU](#Ô∏è-componentes-da-cpu)
  - [Pipeline MIPS](#pipeline-mips-de-5-est√°gios)
  - [ULA (Unidade L√≥gica Aritm√©tica)](#ula-unidade-l√≥gica-aritm√©tica)
  - [Registradores](#registradores)
  - [Banco de Registradores](#banco-de-registradores)
  - [Unidade de Controle](#unidade-de-controle)
  - [Process Control Block (PCB)](#process-control-block-pcb)
- [Sistema de Mem√≥ria](#-sistema-de-mem√≥ria)
  - [Hierarquia de Mem√≥ria](#hierarquia-de-mem√≥ria-3-n√≠veis)
  - [Mem√≥ria Principal (RAM)](#mem√≥ria-principal-ram)
  - [Mem√≥ria Secund√°ria (Disco/Swap)](#mem√≥ria-secund√°ria-discoswap)
  - [Cache L1](#cache-l1)
  - [Pol√≠ticas de Substitui√ß√£o](#pol√≠ticas-de-substitui√ß√£o-fifolru)
  - [Segmenta√ß√£o (Modelo Tanenbaum)](#segmenta√ß√£o-modelo-tanenbaum)
- [Pol√≠ticas de Escalonamento](#-pol√≠ticas-de-escalonamento)
- [Rastreamento Temporal de Mem√≥ria](#Ô∏è-rastreamento-temporal-de-mem√≥ria)
- [Sistema de I/O](#-sistema-de-io)
- [M√©tricas de Desempenho](#-m√©tricas-de-desempenho)
- [Lote Inicial de Processos](#-lote-inicial-de-processos)
- [Como Compilar e Executar](#-como-compilar-e-executar)
  - [Instala√ß√£o R√°pida](#instala√ß√£o-r√°pida)
  - [Comandos Dispon√≠veis](#comandos-dispon√≠veis)
  - [Executando o Simulador](#executando-o-simulador)
- [Visualiza√ß√£o de Resultados](#-visualiza√ß√£o-de-resultados)
- [Configura√ß√£o do Ambiente (Docker/WSL)](#-configura√ß√£o-do-ambiente-dockerwsl)
- [Estrutura do Projeto](#Ô∏è-estrutura-do-projeto)
- [Decis√µes de Projeto](#-decis√µes-de-projeto)
- [Colaboradores](#-colaboradores)
- [üìÑ Licen√ßa](#-licen√ßa)
- [üìö Refer√™ncias](#-refer√™ncias)

---

## Sobre o Projeto

<div align="justify">

Este projeto implementa um **simulador completo de arquitetura multicore Von Neumann** com pipeline MIPS, desenvolvido em duas fases para a disciplina de Sistemas Operacionais:

### Evolu√ß√£o do Simulador

**Fase 1 - Trabalho de Aquecimento (Base):**
- Implementa√ß√£o da arquitetura Von Neumann cl√°ssica
- Pipeline MIPS de 5 est√°gios (IF ‚Üí ID ‚Üí EX ‚Üí MEM ‚Üí WB)
- Componentes b√°sicos: ULA, Registradores, Mem√≥rias
- Sistema de I/O com dispositivos perif√©ricos
- Divis√£o por equipes: CPU, Mem√≥rias, Perif√©ricos, Suporte

**Fase 2 - Trabalho Final (Extens√µes):**
- **Arquitetura Multicore**: At√© 8 n√∫cleos com threads C++ reais
- **Gerenciamento de Mem√≥ria Avan√ßado**: Segmenta√ß√£o Tanenbaum + Cache L1 (FIFO/LRU)
- **Pol√≠ticas de Escalonamento**: FCFS, SJN, Priority, Round Robin
- **Rastreamento Temporal**: Snapshots de mem√≥ria a cada 10 ciclos
- **M√©tricas Completas**: Tempo de espera, retorno, throughput, cache hit rate
- **Visualiza√ß√£o**: 12 gr√°ficos comparativos gerados automaticamente

### Conformidade com o Enunciado

O simulador atende **100% dos requisitos t√©cnicos** especificados no trabalho final:

| Requisito | Implementa√ß√£o |
|-----------|---------------|
| Arquitetura Multicore (1-8 cores)  | `std::thread` com sincroniza√ß√£o mutex |
| Lote inicial de programas  | 9 processos carregados do disco |
| Mem√≥ria compartilhada unificada  | Acesso sincronizado entre cores |
| Segmenta√ß√£o Tanenbaum  | 4 segmentos (CODE, DATA, STACK, HEAP) |
| Pol√≠ticas de substitui√ß√£o  | FIFO e LRU implementadas |
| 4 Pol√≠ticas de escalonamento  | FCFS, SJN, Priority, RR |
| Cen√°rio n√£o-preemptivo  | FCFS, SJN, Priority (run-to-completion) |
| Cen√°rio preemptivo  | Round Robin (quantum=5 ciclos) |
| M√©tricas de desempenho  | Todas as m√©tricas especificadas |
| Relat√≥rios de escalonamento  | Compara√ß√£o entre pol√≠ticas |
| Utiliza√ß√£o temporal de mem√≥ria  | Snapshots autom√°ticos + relat√≥rios |

### Componentes Implementados

| Componente | Descri√ß√£o | 
|------------|-----------|
| **Pipeline MIPS** | 5 est√°gios (Fetch ‚Üí Decode ‚Üí Execute ‚Üí Memory ‚Üí WriteBack) |
| **Multicore** | 1-8 cores com threads C++ e sincroniza√ß√£o | 
| **Escalonamento** | 4 pol√≠ticas (FCFS, SJN, Priority, RR) | 
| **Mem√≥ria Segmentada** | Modelo Tanenbaum com 4 segmentos | 
| **Cache FIFO/LRU** | Pol√≠ticas de substitui√ß√£o implementadas |
| **Hierarquia Mem√≥ria** | 3 n√≠veis (Cache ‚Üí RAM ‚Üí Swap) | 
| **Rastreamento Temporal** | Snapshots a cada 10 ciclos | 
| **Relat√≥rios** | Individuais e agregados do sistema | 
| **Visualiza√ß√£o** | 12 gr√°ficos comparativos (Python/matplotlib) | 

</div>

---

## Fundamentos da Arquitetura Von Neumann

<div align="justify">

Segundo a proposta do trabalho, a **arquitetura de Von Neumann**, concebida por John von Neumann na d√©cada de 1940, constitui a base conceitual dos sistemas computacionais modernos. Essa arquitetura caracteriza-se pelo uso de uma **√∫nica mem√≥ria compartilhada** para armazenamento de dados e instru√ß√µes, caracter√≠stica que origina o fen√¥meno conhecido como **Von Neumann bottleneck**.

Essa limita√ß√£o decorre do fato de que processador e mem√≥ria disputam o mesmo barramento de comunica√ß√£o, restringindo a taxa de transfer√™ncia e, consequentemente, comprometendo o desempenho do sistema.

### Solu√ß√µes Implementadas para Mitigar o Bottleneck

Com o intuito de mitigar esse problema, a evolu√ß√£o da computa√ß√£o incorporou solu√ß√µes fundamentadas na **organiza√ß√£o hier√°rquica da CPU, dos barramentos e da mem√≥ria**:

1. **Mem√≥ria Cache**: Atua como intermedi√°ria entre CPU e RAM, com elevada velocidade de acesso e capacidade limitada, armazenando dados frequentemente utilizados.

2. **Pipeline MIPS**: Permite execu√ß√£o sobreposta de instru√ß√µes, aumentando throughput sem aumentar frequ√™ncia de clock.

3. **Arquitetura Multicore**: M√∫ltiplos n√∫cleos compartilham a mem√≥ria, permitindo paralelismo real.

4. **Hierarquia de Mem√≥ria**: Tr√™s n√≠veis (Cache L1 ‚Üí RAM ‚Üí Swap) com diferentes velocidades e capacidades.

5. **DMA (Direct Memory Access)**: Acesso direto √† mem√≥ria por dispositivos perif√©ricos sem interven√ß√£o da CPU.

### Diagrama da Arquitetura Base

Este trabalho foi baseado no seguinte diagrama proposto de arquitetura:

</div>

<div align="center">

![Arquitetura](imgs/arquitetura.png)

</div>

<div align="justify">

### Divis√£o em Equipes (Fase 1)

Para a elabora√ß√£o deste trabalho, a turma foi dividida em 4 grupos especializados:

- **Equipe CPU**: Implementa√ß√£o da CPU com pipeline MIPS e conjunto de instru√ß√µes
- **Equipe Mem√≥rias**: Implementa√ß√£o das mem√≥rias principal, secund√°ria e cache
- **Equipe Perif√©ricos**: Dispositivos de I/O, parser JSON e programas de teste
- **Equipe Suporte**: Integra√ß√£o dos sistemas, documenta√ß√£o, Docker e gerenciamento

</div> 

 



## Organiza√ß√£o do Reposit√≥rio
Com base nos arquivos gerados, podemos definir propriamente em qual parte da arquitetura cada um deles pertence, como ficou definido no resumo a seguir:

### Arquivos da CPU
#### Unidade de Controle (UC):
- `CONTROL_UNIT.cpp`
- `CONTROL_UNIT.hpp`
#### PCB:
- `PCB.hpp`
- `pcb_loader.cpp`
- `pcb_loader.hpp`
#### Registradores:
- `HASH_REGISTER.hpp`
- `REGISTER.hpp`
- `REGISTER_BANK.cpp`
- `REGISTER_BANK.hpp`
#### Unidade L√≥gica e Aritm√©tica (ULA):
- `ULA.cpp`
- `ULA.hpp`
- `ULA.o`



### Arquivos das Mem√≥rias
#### Mem√≥rias principal e secund√°ria:
- `MAIN_MEMORY.hpp`
- `MAIN_MEMORY.cpp`
- `SECONDARY_MEMORY.hpp`
- `SECONDARY_MEMORY.cpp`



### Arquivos Cache (Mem√≥ria Cache)
- `cache.hpp`
- `cache.cpp`
- `cachePolicy.hpp`
- `cachePolicy.cpp`



### Arquivos dos Perif√©ricos
- `IOManager.hpp`
- `IOManager.cpp`



## Sobre a CPU

### `ULA.hpp/.cpp`:

<div align="justify">
<p>A Unidade L√≥gica Aritm√©tica √© o componente respons√°vel por realizar as opera√ß√µes necess√°rias (sendo estas matem√°ticas e l√≥gicas) para o entendimento da m√°quina acerca das instru√ß√µes.</p>

<p>Esta √© essencial para a estrutura e comportamento de toda m√°quina, visto que ela opera os n√∫meros bin√°rios √† baixo n√≠vel. H√°-se tamb√©m uma <i>flag</i> nomeada como <b>overflow</b>, que indica caso o resultado ultrapasse a capacidade de interpreta√ß√£o da ULA. Dentre as opera√ß√µes implementadas, temos:</p>
</div>


#### ADD:
* **Tipo:** Aritm√©tica
* **Descri√ß√£o:** Soma dois operandos e armazena o resultado. (com detec√ß√£o de overflow signed)
#### SUB
* **Tipo:** Aritm√©tica
* **Descri√ß√£o:** Subtrai o segundo operando em rela√ß√£o ao primeiro e armazena o resultado. (com detec√ß√£o de overflow signed)
#### MUL
* **Tipo:** Aritm√©tica
* **Descri√ß√£o:** Multiplica dois operandos e armazena o resultado. (com detec√ß√£o de overflow signed)
#### DIV
* **Tipo:** Aritm√©tica
* **Descri√ß√£o:** Divide o primeiro operando em rela√ß√£o ao segundo e armazena o resultado. (com detec√ß√£o de overflow signed, trata divis√£o por zero).
#### AND_OP
* **Tipo:** L√≥gica
* **Descri√ß√£o:** Compara os dois operandos como uma porta l√≥gica "AND" e armazena o resultado. (tratando ambos como unsigned)
#### BEQ (Branch if Equal)
* **Tipo:** L√≥gica
* **Descri√ß√£o:** Compara os dois operandos, resulta 1 se forem iguais e 0 caso contr√°rio. 
#### BNE (Branch if Not Equal)
* **Tipo:** L√≥gica
* **Descri√ß√£o:** Compara os dois operandos, resulta 1 se forem distintos e 0 caso contr√°rio.
#### BLT (Branch if Less Than)
* **Tipo:** L√≥gica
* **Descri√ß√£o:** Compara os dois operandos, resulta 1 se o primeiro operando for **menor** que o segundo, e 0 caso contr√°rio.  (signed)
#### BGT (Branch if Greater Than)
* **Tipo:** L√≥gica
* **Descri√ß√£o:** Compara os dois operandos, resulta 1 se o primeiro operando for **maior** que o segundo, e 0 caso contr√°rio. (signed)
#### BGTI (Branch if Greater Than Immediate)
* **Tipo:** L√≥gica
* **Descri√ß√£o:** Compara os dois operandos, resulta 1 se o primeiro operando for **maior** que o segundo, e 0 caso contr√°rio. (Conven√ß√£o do operando B [segundo] conter o imediato)
#### BLTI (Branch if Less Than Immediate)
* **Tipo:** L√≥gica
* **Descri√ß√£o:** Compara os dois operandos, resulta 1 se o primeiro operando for **menor** que o segundo, e 0 caso contr√°rio. (Conven√ß√£o do operando B [segundo] conter o imediato)
* OBS: Todas opera√ß√µes do tipo Branch realizam **salto** de instru√ß√£o;
#### LW (Load Word)
- **Tipo:** Dados
- **Descri√ß√£o:** Carrega um valor da mem√≥ria para um registrador
#### LA (Load Address)
- **Tipo:** Dados
- **Descri√ß√£o:** Carrega um endere√ßo da mem√≥ria para um registrador
#### ST (Store)
- **Tipo:** Dados
- **Descri√ß√£o:** Armazena um valor de um registrador para uma posi√ß√£o na mem√≥ria.
### Atributos:

- `A`,¬†`B`: Entradas A e B da ALU, que recebem operandos de 32 bits (atrav√©s do uint_32).
- `result`: Resultado da opera√ß√£o (32 bits signed).
- `overflow`: Flag de overflow.
- `op`: Opera√ß√£o a ser realizada.
### Fun√ß√µes:
- `calculate()`: Executa a opera√ß√£o especificada.
- `execute():` Recebe os operandos e a opera√ß√£o para realizar o c√°lculo.

## `REGISTER.hpp/.cpp`:

<div align="justify">
<p>Unidade individual de armazenamento, usado de diversas maneiras como para armazenas dados tempor√°rios utilizados pela ULA, endere√ßos de mem√≥rias para busca dentro da mesma e informa√ß√µes de controle para funcionamento completo da estrutura.</p>
</div>

O registrador possui:
- `value:` o valor do registrador, representado por um uint_32 (uma palavra de 32 bits), e inicializado em 0 por conven√ß√£o atrav√©s do construtor.
- `write():` respons√°vel por escrever um novo valor no registrador. (OBS: sem prote√ß√£o de escritad no R0)
 - `read():` respons√°vel por retornar o valor atual do registrador, utiliza-se *const* para evitar a modifica√ß√£o do registrador.
 - `reverse_read():` respons√°vel por retornar o valor com os bytes invertidos (chamado *endianness swap*). 


## `HASH_REGISTER.hpp/.cpp`:

<div align="justify">
<p>Estes arquivos s√£o respons√°veis por fazer o mapeamento dos registradores utilizados pela Unidade de Controle. Tem-se a implementa√ß√£o completa e correta da especifica√ß√£o MIPS R3000/R4000:</p>

- R0 (zero): Sempre cont√©m 0 (hardwired)
- R1 (at): Assembler tempor√°rio
- R2-R3 (v0-v1): Resultados de Fun√ß√£o
- R4-R7 (a0-a3): Argumentos de Fun√ß√£o
- R8-R15 (t0-t7): Registradores Tempor√°rios
- R16-R23 (s0-s7): Registradores de Salvamento
- R24-R25 (t8-t9): Mais Registradores Tempor√°rios
- R26-R27 (k0-k1): Reservado para o Kernel
- R28-R31 (gp, sp, fp, ra): Prop√≥sitos Especiais
	- R0 -> R31: Registradores de **prop√≥sito geral**
	- Registradores especiais: **PC, MAR, IR, HI, LO, SR, EPC, CR**

Utilizou-se std::unordered_map (com custo de O(1) amortizado) para melhoria da performance de acesso aos registradores. E uma implementa√ß√£o de aux√≠lio para acessos mais r√°pidos e frequentes.

Todo registrador possui um **nome, tipo, uma vari√°vel de disponibilidade e uma descri√ß√£o**.  

Tem-se na classe de `RegisterMapper`, mapas bidirecionais para uma performance otimizada de busca. Sendo eles de *bin√°rio para nome/nome para bin√°rio e um com os metadados dos registradores.*


## `REGISTER_BANK(.hpp e .cpp)`:

<div align="justify">
<p>O banco de registradores √©, na teoria, **a mem√≥ria mais r√°pida da CPU**. Ele funciona como uma "mesa de trabalho" para o processador, guardando os dados que est√£o sendo usados no momento, como o resultado de uma soma ou o endere√ßo da pr√≥xima instru√ß√£o.</p>

<p>Na pr√°tica, aqui no nosso c√≥digo, o REGISTER_BANK √© uma <b>classe que agrupa todos os registradores do MIPS como objetos individuais</b>. A ideia √© que, em vez de acessar um registrador por um n√∫mero (como o registrador 16), a Control Unit pode simplesmente pedir pelo nome ("s0"), usando os mapas que a gente criou. Isso deixa o c√≥digo do resto do grupo muito mais f√°cil de ler e entender.</p>

**Registradores de uso espec√≠fico:** 
- `REGISTER pc, mar, cr, epc, sr, hi, lo, ir;`

**Registradores de uso geral:** 
- `REGISTER zero, at; REGISTER v0, v1; REGISTER a0, a1, a2, a3; REGISTER t0, t1, t2, t3, t4, t5, t6, t7, t8, t9; REGISTER s0, s1, s2, s3, s4, s5, s6, s7; REGISTER k0, k1; REGISTER gp, sp, fp, ra;`
## Fun√ß√µes:
- `REGISTER_BANK()`: Ele preenche os mapas que associam os nomes dos registradores (ex: "t0")  √†s suas fun√ß√µes de leitura e escrita. √â aqui que a m√°gica do acesso por nome acontece.
- `readRegister()`: L√™ um registrador usando o nome como string. Lan√ßa um erro se o nome for inv√°lido.
- `writeRegister()`: Escreve em um registrador usando o nome. A prote√ß√£o do registrador "zero" √© garantida aqui.
- `reset()`: Zera todos os registradores. Serve para limpar o estado da CPU entre processos.
- `print_registers()`: Fun√ß√£o de ajuda para debug. Imprime o valor de todos os registradores de forma organizada na tela.

## PCB.hpp (Formato e M√©tricas)

**Campos principais (resumo)**:
- `pid` (int): identificador √∫nico do processo.
- `state` (enum): {NEW, READY, RUNNING, BLOCKED, TERMINATED}.
- `priority` (int): prioridade do processo (maior valor = maior prioridade).
- `quantum` (int): fatia de tempo (em ciclos) para escalonador round-robin.
- `cache_hits` / `cache_misses` (uint64): contadores de cache por processo.
- `memory_cycles` (uint64): contagem de ciclos atribu√≠dos a acessos √† mem√≥ria para este processo.
- `io_cycles` (uint64): contagem de ciclos gastos em I/O.

**MemWeights**
- Conjunto de pesos (`memWeights.cache`, `memWeights.main`, `memWeights.secondary`) usado para calcular custo em ciclos quando o processo acessa cada camada de mem√≥ria.

**JSON de entrada (pcb_loader)**
- O `pcb_loader` aceita um JSON com chaves obrigat√≥rias: `pid`, `priority`, `quantum`, `initial_pc` e opcional `memWeights`. Exemplo:
```json
{
  "pid": 1,
  "priority": 5,
  "quantum": 5,
  "initial_pc": 0,
  "memWeights": { "cache": 1, "main": 10, "secondary": 100 }
}
```

## `CONTROL_UNIT.hpp/.cpp`:

<div align="justify">
<p>A Unidade de Controle √© uma das partes mais cruciais da CPU que coordena e gerencia a execu√ß√£o de instru√ß√µes no processador. Ela atua como o centro pensativo da CPU, determinando quais opera√ß√µes devem ser realizadas, em qual ordem e com quais dados. As instru√ß√µes citadas no ciclo da CPU e da Pipeline s√£o definidas e realizadas aqui, na ordem necess√°ria e solicitada pelo sistema.</p>

<p>L√™ instru√ß√µes da mem√≥ria, decodifica quais registradores e imediatos usar, manda as opera√ß√µes para a ULA (ALU), faz acesso √† mem√≥ria (load/store) e gera pedidos de I/O (print). Tudo isso dividido em 5 etapas (pipeline): IF, ID, EX, MEM, WB.</p>

### Helpers:
- `binaryStringToUint(...)`  -> transforma uma string de '0'/'1' em n√∫mero.
- `signExtend16(...)`  -> transforma um imediato de 16 bits em 32 bits preservando o sinal (two's complement).

### Utilit√°rios para extrair campos da instru√ß√£o de 32 bits:
- `Get_immediate(...)`  -> pega os 16 bits de imediato.
- `Pick_Code_Register_Load(...)`  -> pega o campo rt (bits 11..15).
- `Get_destination_Register(...)` -> pega rd (bits 16..20).
- `Get_target_Register(...)`  -> pega rt (bits 11..15).
- `Get_source_Register(...) `  -> pega rs (bits 6..10).

O Ciclo implementado no MIPS (atrav√©s do pseudoparalelismo de pipeline) h√°-se descrito a seguir:
- `void Fetch(ControlContext &context):` busca instru√ß√£o da mem√≥ria;
- `void Decode(REGISTER_BANK &registers, Instruction_Data &data):`  decodifica campos;
- `void Execute_Aritmetic_Operation(REGISTER_BANK &registers, Instruction_Data &d):` usa ULA para ALU-ops;
- `void Execute_Operation(Instruction_Data &data, ControlContext &context):`  branches /saltos / syscalls (chamadas do sistema);
- `void Execute_Loop_Operation(REGISTER_BANK &registers, Instruction_Data &d,int &counter, int &counterForEnd, bool &endProgram, MainMemory &ram, PCB &process):`Loop principal;
- `void Execute(Instruction_Data &data, ControlContext &context):`  dispatcher de execu√ß√£o;
- `void Memory_Acess(Instruction_Data &data, ControlContext &context):` LW / SW (depende de MainMemory);
- `void Write_Back(Instruction_Data &data, ControlContext &context);`  grava resultado no banco de registradores;
### Acerca da Execu√ß√£o
- **Identifica√ß√£o de instru√ß√£o:**
	- `Identificacao_instrucao(...)` -> l√™ os 6 bits do opcode e tenta retornar uma string com o nome da instru√ß√£o ("ADD", "LW", "J", ...). *OBS:* o mapeamento est√° simplificado; R-type com opcode 000000 tenta usar o campo 'funct' para inferir ADD/SUB/MULT/DIV.
  - **Est√°gios do pipeline (explica√ß√£o direta):**
      * Fetch(context)   -> busca a instru√ß√£o na mem√≥ria usando o PC e escreve em IR. Tamb√©m detecta um sentinel de fim de programa.
      * Decode(regs, d)  -> l√™ a IR, identifica o mnemonic e preenche os campo em Instruction_Data (registradores, imediato, etc).   Faz sign-extend dos imediatos quando necess√°rio.
      * Execute(...)     -> dispatcher que decide qual execu√ß√£o fazer:
		   - Execute_Aritmetic_Operation(...) para ADD/SUB/...
		   - Execute_Loop_Operation(...) para BEQ/J/BLT/...
		   - Execute_Operation(...) para PRINT / I/O
	* Memory_Acess(...)-> realiza LW, SW, LA, LI e leitura para PRINT de endere√ßos de mem√≥ria.
      * Write_Back(...)  -> grava na mem√≥ria em caso de SW (ou outros writes se adicionados).



## Sobre as Mem√≥rias
Neste m√≥dulo da mem√≥ria do simulador est√° dividido em tr√™s componentes principais:

- **Mem√≥ria Principal (RAM)** ‚Äî implementada em [`MAIN_MEMORY.hpp`](src/memory/MAIN_MEMORY.hpp) e [`MAIN_MEMORY.cpp`](src/memory/MAIN_MEMORY.cpp).  
- **Mem√≥ria Secund√°ria (disco/armazenamento permanente)** ‚Äî implementada em [`SECONDARY_MEMORY.hpp`](src/memory/SECONDARY_MEMORY.hpp) e [`SECONDARY_MEMORY.cpp`](src/memory/SECONDARY_MEMORY.cpp).  
- **Gerenciador de Mem√≥ria (MemoryManager)** ‚Äî interface que unifica acesso √†s duas mem√≥rias e faz a tradu√ß√£o de endere√ßos l√≥gicos para cada espa√ßo. Implementado em [`MemoryManager.hpp`](src/memory/MemoryManager.hpp) e [`MemoryManager.cpp`](src/memory/MemoryManager.cpp).

---

### MAIN_MEMORY
**Papel:** simular a mem√≥ria principal (RAM) como um vetor linear de palavras (`vector<uint32_t>`).

**Comportamento principal (fun√ß√µes):**
- **Construtor** ‚Äî [`MAIN_MEMORY::MAIN_MEMORY`](src/memory/MAIN_MEMORY.cpp#L3) recebe o tamanho desejado, ajusta pelo `MAX_MEMORY_SIZE` e inicializa com `MEMORY_ACCESS_ERROR`.  
- [`isEmpty()`](src/memory/MAIN_MEMORY.cpp#L18) ‚Äî percorre o vetor e retorna `true` se todas as posi√ß√µes forem `0`.  
- [`notFull()`](src/memory/MAIN_MEMORY.cpp#L25) ‚Äî verifica se existe alguma posi√ß√£o igual a `0` (h√° espa√ßo livre).  
- [`ReadMem(uint32_t address)`](src/memory/MAIN_MEMORY.cpp#L32) ‚Äî retorna o conte√∫do em `address` se v√°lido; sen√£o `MEMORY_ACCESS_ERROR`.  
- [`WriteMem(uint32_t address, uint32_t data)`](src/memory/MAIN_MEMORY.cpp#L39) ‚Äî escreve `data` se `address` v√°lido; caso contr√°rio retorna `MEMORY_ACCESS_ERROR`.  
- [`DeleteData(uint32_t address)`](src/memory/MAIN_MEMORY.cpp#L49) ‚Äî devolve o valor salvo e marca a c√©lula com `MEMORY_ACCESS_ERROR`.

A RAM √© representada por um `vector<uint32_t> ram` redimensionado para `size`. Inicialmente todas as posi√ß√µes s√£o preenchidas com `MEMORY_ACCESS_ERROR`.  

---

### SECONDARY_MEMORY
**Papel:** simular a mem√≥ria secund√°ria (disco) como uma estrutura 2D (matriz).

**Comportamento principal (fun√ß√µes):**
- **Construtor** ‚Äî [`SECONDARY_MEMORY::SECONDARY_MEMORY`](src/memory/SECONDARY_MEMORY.cpp#L3) limita o tamanho a `MAX_SECONDARY_MEMORY_SIZE`, calcula `rowSize` e inicializa `storage` com `MEMORY_ACCESS_ERROR`.  
- [`isEmpty()`](src/memory/SECONDARY_MEMORY.cpp#L19) ‚Äî percorre todas as c√©lulas e retorna `true` se todas forem `0`.  
- [`notFull()`](src/memory/SECONDARY_MEMORY.cpp#L27) ‚Äî retorna `true` se houver alguma c√©lula igual a `0`.  
- [`ReadMem(uint32_t address)`](src/memory/SECONDARY_MEMORY.cpp#L45) ‚Äî converte `address` em `(row, col)` e retorna o conte√∫do se v√°lido; sen√£o `MEMORY_ACCESS_ERROR`.  
- [`WriteMem(uint32_t address, uint32_t data)`](src/memory/SECONDARY_MEMORY.cpp#L52) ‚Äî escreve `data` na c√©lula se v√°lido; sen√£o `MEMORY_ACCESS_ERROR`.  
- [`DeleteData(uint32_t address)`](src/memory/SECONDARY_MEMORY.cpp#L62) ‚Äî devolve o valor e marca a c√©lula com `MEMORY_ACCESS_ERROR`.

A implementa√ß√£o usa uma **matriz quadrada** baseada em `sqrt(MAX_SECONDARY_MEMORY_SIZE)`.  
Para converter um endere√ßo linear em coordenadas da matriz, s√£o usados os m√©todos  
[`getRow(uint32_t address)`](src/memory/SECONDARY_MEMORY.cpp#L35), que retorna a linha (`address / rowSize`),  
e [`getCol(uint32_t address)`](src/memory/SECONDARY_MEMORY.cpp#L40), que retorna a coluna (`address % rowSize`).  
Esses m√©todos garantem que cada posi√ß√£o linear seja mapeada corretamente dentro da estrutura 2D da mem√≥ria secund√°ria.

<!-- 
---
### MemoryManager
**Papel:** camada de abstra√ß√£o que unifica leituras e escritas.

.......... -->

---

### Comportamento de erro e marca√ß√£o de c√©lulas
- Em opera√ß√µes inv√°lidas (endere√ßo fora do limite) as fun√ß√µes retornam `MEMORY_ACCESS_ERROR`.  
- Em dele√ß√µes bem-sucedidas, a c√©lula √© marcada com `MEMORY_ACCESS_ERROR`.
do)






## Cache (Mem√≥ria Cache)

Seu objetivo √© reduzir o tempo m√©dio de acesso √† mem√≥ria principal (RAM), diminuindo a lat√™ncia do processador. A cache funciona como um intermedi√°rio inteligente entre a CPU e a mem√≥ria principal, utilizando bits de controle como `isValid` e `isDirty` para gerenciar a coer√™ncia e consist√™ncia dos dados.  
O bit `isValid` garante que uma linha possui dados utiliz√°veis, enquanto o `isDirty` indica modifica√ß√µes ainda n√£o propagadas √† RAM (write-back pendente).

### Estrutura da Cache

| Data | isValid | isDirty |
|------|---------|---------|
| Valor armazenado | V√°lido? | Sujo? |

- **Data** ‚Äî Valor efetivo armazenado (dado real).  
- **isValid** ‚Äî Indica se a entrada cont√©m um dado v√°lido.  
- **isDirty** ‚Äî Indica se o dado foi alterado na cache e ainda n√£o foi gravado na mem√≥ria principal.  

---

**Endere√ßamento e granularidade**
- `address` nas fun√ß√µes p√∫blicas da cache representa um *√≠ndice de palavra* (word address). Cada palavra tem 4 bytes. Se chamar `Cache::get(0)` retorna o conte√∫do da primeira palavra. (Se o teu c√≥digo usa bytes, converte `byte_offset/4` antes de usar a cache.)

**M√©tricas**
- `get_hits()` e `get_misses()` retornam os contadores agregados desde a inicializa√ß√£o. Reset manual pode ser feito re-criando o objeto `Cache` ou adicionando um m√©todo `resetMetrics()`.

### Comportamento principal (fun√ß√µes)

- **Construtor** ‚Äî [`Cache::Cache`](src/memory/cache.cpp#L5) inicializa a estrutura com a capacidade m√°xima e zera m√©tricas (`cache_hits`, `cache_misses`).  

- [`Cache::get(size_t address)`](src/memory/cache.cpp#L16) busca o dado pelo `address`/`tag`.  
  - Se encontrar com `isValid = true` ‚Üí **cache hit** (retorna o valor e incrementa `cache_hits`).  
  - Caso contr√°rio ‚Üí **cache miss** (retorna `CACHE_MISS` e incrementa `cache_misses`).  

- [`Cache::put(size_t address, size_t data, MemoryManager* memManager)`](src/memory/cache.cpp#L26) insere/substitui bloco.  
  - Se a cache estiver cheia, aplica **FIFO (First In, First Out)**.  
  - Se o bloco removido estiver **sujo** (`isDirty = true`), faz **write-back** via `MemoryManager`.  
  - Insere `{ data, isValid = true, isDirty = false }` e atualiza a fila FIFO.  

- [`Cache::update(size_t address, size_t data)`](src/memory/cache.cpp#L58) atualiza uma linha existente.  
  - Marca como **suja** (`isDirty = true`) e mant√©m `isValid = true`.  
  - Se o endere√ßo n√£o existir, **n√£o** faz write-allocate.  

- [`Cache::invalidate()`](src/memory/cache.cpp#L73) define `isValid = false` em todas as entradas e esvazia a fila FIFO (reset/troca de contexto).  

- [`Cache::dirtyData()`](src/memory/cache.cpp#L82) retorna `{address, data}` de todas as linhas **sujas**, √∫til para **flush** consistente para a mem√≥ria principal.  

---

### Pol√≠tica de substitui√ß√£o

A [`CachePolicy`](src/memory/cachePolicy.cpp) define a estrat√©gia quando a cache atinge a capacidade.  
A implementa√ß√£o atual usa **FIFO (First In, First Out)**: **o primeiro bloco inserido √© o primeiro a ser removido** (sem considerar acessos recentes).

- [`CachePolicy::getAddressToReplace(std::queue<size_t>& fifo_queue)`](src/memory/cachePolicy.cpp#L8) indica **qual endere√ßo remover**.  
  - Se `fifo_queue` estiver vazia, retorna `-1`.  
  - Caso contr√°rio, retorna e remove o **primeiro endere√ßo inserido** na fila (seguindo a pol√≠tica FIFO).  


**Pol√≠tica de escrita**
- A cache implementa **write-back** com **no-write-allocate**:
  - `Cache::update(address, data)` marca a linha como *suja* (`isDirty = true`) se a entrada existir.
  - Se a entrada n√£o existir, **n√£o** aloca (n√£o faz write-allocate). Em seguida deve ocorrer write direto √† mem√≥ria via `MemoryManager` (comportamento atual do sistema).

**Substitui√ß√£o**
- Pol√≠tica: **FIFO** (primeiro a entrar, primeiro a sair).  
- Ao substituir, se a linha removida estiver `isDirty=true`, a cache chama `MemoryManager::writeToFile` para write-back.


---

### Estrutura interna

A cache usa **`std::unordered_map`** para mapeamento `{address ‚Üí CacheEntry}`, permitindo **acessos diretos e eficientes (O(1))** aos endere√ßos armazenados.  
Isso melhora a performance global do sistema de mem√≥ria, pois garante que as opera√ß√µes de leitura, escrita e verifica√ß√£o de presen√ßa na cache sejam r√°pidas, otimizando o desempenho.


## Sobre os Perif√©ricos e I/O
### Estrutura dos Arquivos

* `IOManager.h`: Arquivo de cabe√ßalho da classe `IOManager`. Define a interface p√∫blica e os membros privados.
* `IOManager.cpp`: Arquivo de implementa√ß√£o da classe `IOManager`. Cont√©m toda a l√≥gica de funcionamento do gerenciador.
* `shared_structs.h`: Define estruturas de dados e enums (`PCB`, `IORequest`, `State`) que s√£o compartilhados entre o `IOManager` e outros m√≥dulos.
* `main.cpp`: **Arquivo de simula√ß√£o e exemplo de uso.** Ele cria um ambiente com processos e um escalonador para demonstrar a intera√ß√£o com o `IOManager`. main inicializa a configura√ß√£o via CLI, carrega processos do ficheiro JSON, cria PCBs e inicializa os subsistemas (Cache, MemoryManager, Control Unit, Scheduler). Em seguida entra no loop de simula√ß√£o: o scheduler seleciona processos, faz context switch, e a unidade de controle executa instru√ß√µes ciclo-a-ciclo (fetch ‚Üí decode ‚Üí execute ‚Üí memory ‚Üí write-back), contabilizando m√©tricas (ciclos, cache hits/misses). Ao t√©rmino, main faz flush das linhas sujas da cache, escreve estat√≠sticas e finaliza. Flags como --time-slice, --cache-capacity, --max-cycles controlam comportamento de runtime.



### Arquitetura do Projeto

O projeto do I/O √© dividido em duas partes principais:

1.  **O M√≥dulo `IOManager`**: √â o n√∫cleo deste trabalho. Sua responsabilidade agora √© dupla:
    * **Simular Dispositivos**: Ele simula hardware (como impressora e disco) que, de forma independente, solicitam opera√ß√µes de I/O.
    * **Gerenciar Processos**: Ele mant√©m uma fila de processos que est√£o bloqueados esperando por I/O e os atribui aos dispositivos que se tornam ativos. Ele gera as requisi√ß√µes de I/O internamente.

2.  **O Ambiente de Simula√ß√£o (`main.cpp`)**: Este c√≥digo **n√£o faz parte** do m√≥dulo `IOManager`. Ele atua como um "cliente" que utiliza o gerenciador, simulando:
    * A cria√ß√£o de Processos (PCBs).
    * Um escalonador de CPU (Round-Robin simples).
    * A decis√£o de um processo de solicitar uma opera√ß√£o de I/O, momento em que ele se "registra" no `IOManager` e fica bloqueado.

### M√©todos Principais do `IOManager.cpp`

#### 1. `void IOManager::registerProcessWaitingForIO(PCB* process)`

Este √© o **novo ponto de entrada** do `IOManager`. √â a √∫nica fun√ß√£o p√∫blica usada por sistemas externos para interagir com o gerenciador.

* **Responsabilidade**: Adicionar de forma segura um processo que entrou em estado `Blocked` a uma lista de espera interna.
* **Funcionamento**:
    1.  Recebe um ponteiro para o PCB do processo que precisa de I/O.
    2.  Utiliza um `std::lock_guard<std::mutex>` para bloquear o acesso √† lista `waiting_processes` e evitar condi√ß√µes de corrida.
    3.  Adiciona o processo √† lista de espera.

#### 2. `void IOManager::managerLoop()`

√â uma fun√ß√£o privada que executa em um loop infinito dentro de sua pr√≥pria thread, representando o ciclo de vida do gerenciador. Sua l√≥gica foi expandida e agora opera em tr√™s etapas principais a cada itera√ß√£o:

* **Responsabilidade**: Simular dispositivos, combinar processos em espera com dispositivos ativos, criar requisi√ß√µes de I/O e process√°-las.
* **Funcionamento**:
    1.  **Etapa 1: Simula√ß√£o de Dispositivos**
        * De forma aleat√≥ria, o loop pode alterar o estado de um dos dispositivos (ex: `printer_requesting`) de `false` para `true`. Isso simula um perif√©rico que agora precisa de servi√ßo, representando o "estado 1" que foi solicitado.

    2.  **Etapa 2: Verifica√ß√£o e Cria√ß√£o de Requisi√ß√µes**
        * O gerenciador verifica duas condi√ß√µes simultaneamente: se h√° algum dispositivo com estado `true` E se h√° algum processo na `waiting_processes`.
        * Se ambas forem verdadeiras, ele "combina" os dois:
            * Pega o primeiro processo da fila de espera.
            * Cria uma estrutura `IORequest` espec√≠fica para o dispositivo ativo (ex: `operation = "print_job"`).
            * **Atribui um custo aleat√≥rio de 1 a 3** √† requisi√ß√£o.
            * Muda o estado do dispositivo de volta para `false` (ocupado ou atendido).
            * Adiciona a requisi√ß√£o rec√©m-criada √† fila de processamento interna.

    3.  **Etapa 3: Processamento da Requisi√ß√£o**
        * Se a fila de processamento n√£o estiver vazia, a primeira requisi√ß√£o √© retirada.
        * Simula o custo em tempo da opera√ß√£o usando `std::this_thread::sleep_for`.
        * Grava logs no console e nos arquivos `result.dat` e `output.dat`.
        * Ao final, **libera o processo** que estava bloqueado, alterando seu estado de volta para `State::Ready`, permitindo que ele volte a ser escalonado pela CPU.

### Sa√≠das Geradas

* `result.dat`: Um arquivo de log em formato de texto, que descreve cada opera√ß√£o de I/O conclu√≠da.
* `output.dat`: Um arquivo de dados em formato CSV (`id,opera√ß√£o,dura√ß√£o`) para f√°cil importa√ß√£o e an√°lise.



## Configura√ß√£o do WSL e Docker

### Instalando e configurando o Dev Containers no Windows

Antes de come√ßar, verifique se seu sistema atende a estes dois requisitos essenciais:

1.¬† **Vers√£o do Windows:** Voc√™ precisa do Windows 10 (vers√£o 2004 ou mais recente) ou qualquer vers√£o do Windows 11.

2.¬† **Virtualiza√ß√£o Habilitada na BIOS/UEFI:** O WSL 2 precisa que a virtualiza√ß√£o de hardware esteja ativa.

¬† ¬†  **Como verificar:**

¬† ¬† ¬† ¬† 1.¬† Abra o **Gerenciador de Tarefas** (`Ctrl + Shift + Esc`).

¬† ¬† ¬† ¬† 2.¬† V√° para a aba **Desempenho** e clique em **CPU**.

¬† ¬† ¬† ¬† 3.¬† No canto inferior direito, procure por **Virtualiza√ß√£o**. Deve estar **Habilitado**.

![Virtualizador](imgs/virtualizadorhabilitado.png)


¬† **Se estiver desabilitado, voc√™ precisar√° reiniciar o computador, entrar na BIOS/UEFI (geralmente pressionando F2, F10 ou Del durante a inicializa√ß√£o) e ativar a op√ß√£o (pode ter nomes como "Intel VT-x", "AMD-V" ou "SVM Mode").**

---
### Passo 1: Instalar o WSL (Subsistema do Windows para Linux)

1.¬† **Abra o PowerShell como Administrador:**
¬† ¬† * Clique com bot√£o direito no Menu Iniciar, clique em `Windows PowerShell (Admin)` .

2.¬† **Execute o Comando de Instala√ß√£o:**

¬† ¬† * Na janela do PowerShell, digite o seguinte comando e pressione Enter:
```powershell
 wsl --install
```

3.¬† **Reinicie o Computador:**

¬† ¬† * Ap√≥s o comando terminar, ele pedir√° que voc√™ reinicie. Salve seus trabalhos e reinicie.

4.¬† **Instale o Ubuntu:**

```powershell
 ¬†wsl --install -d Ubuntu
```
  

5.¬† **Configure o Ubuntu:**

![Ubuntu](imgs/menuUbuntu.png)

¬† ¬† Ap√≥s a instala√ß√£o procure por Ubuntu no menu iniciar (Pode ser que n√£o seja a mesma vers√£o da image) e clique. Voc√™ precisar√°  configurar rapidamente, ser√° pedido para voc√™ criar um **nome de usu√°rio** e uma **senha** para o seu ambiente Linux. 

---
### O que fazer se o comando `wsl --install` falhar? (O M√©todo Manual)


> Em vers√µes mais antigas do Windows 10 ou em casos espec√≠ficos, o comando √∫nico pode n√£o funcionar. Se isso acontecer, voc√™ pode seguir o m√©todo antigo, que consiste em habilitar as funcionalidades manualmente.

  

**Execute os seguintes comandos no PowerShell como Administrador, um de cada vez:**

  

1.¬† **Habilitar a funcionalidade "Subsistema do Windows para Linux":**

```powershell
dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart¬† ¬† ¬†
```

  

2.¬† **Habilitar a funcionalidade "Plataforma de M√°quina Virtual":**
```powershell
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
```

3.¬† **Reinicie o computador.**

4.¬† **Baixe e instale o pacote de atualiza√ß√£o do kernel do Linux:**

¬† ¬†- [Clique aqui para baixar o pacote do site da Microsoft](https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi). Execute o instalador baixado.


5.¬† **Definir o WSL 2 como padr√£o:**

```powershell
wsl --set-default-version 2
```

6.¬† **Instale o Ubuntu:**

```powershell
wsl --install -d Ubuntu
```
  
7.¬† **Configure o Ubuntu:**

¬† ¬† Ap√≥s a instala√ß√£o procure por Ubuntu no menu iniciar e clique. Voc√™ precisar√°  configurar rapidamente, ser√° pedido para voc√™ criar um **nome de usu√°rio** e uma **senha** para o seu ambiente Linux.
    
---

### Passo 2: Instalar o Docker Desktop
  1.¬† **Baixe o Instalador:**

¬† - V√° para o site oficial: [**docker.com/products/docker-desktop/**](https://www.docker.com/products/docker-desktop/)

2.¬† **Execute o Instalador:**

¬† ¬† - Durante a instala√ß√£o, certifique-se de que a op√ß√£o **"Use WSL 2 instead of Hyper-V (recommended)"** esteja marcada.

3.¬† **Inicie e Configure o Docker Desktop:**

¬† ¬† - Ap√≥s a instala√ß√£o, inicie o Docker Desktop.

¬† ¬† - Fa√ßa um registro r√°pido na plataforma docker hub

¬† ¬† - V√° em **Settings > Resources > WSL Integration**.

¬† ¬† - Certifique-se de que o interruptor para a sua distribui√ß√£o ("Ubuntu") esteja **ligado**.

¬† ¬† - Clique em **"Apply & Restart"**.

![Docker](imgs/docker.png)

---
  
### Passo 3: Instalar e Configurar o Visual Studio Code

1.¬† **Instale a Extens√£o Dev Containers:**

¬† ¬† - No VS Code, v√° para a aba de **Extens√µes** (`Ctrl + Shift + X`).

¬† ¬† - Procure por `Dev Containers` e instale a extens√£o da Microsoft.
  
---
### Passo 4: Testando Tudo!

1.¬† Clone este reposit√≥rio.

2.¬† Clique em **"Reopen in Container"** quando o aviso aparecer, aguarde pois est√°r√° sendo feito o download de todas as dependenciais necess√°rias do container. 

3. Abra o terminal do vscode e digite os seguintes comandos:
- `make teste`
 

## üöÄ Como Compilar e Executar

### Pr√©-requisitos

Para compilar e executar este projeto, voc√™ precisar√° ter os seguintes softwares instalados:

* **g++** (com suporte a C++17)
* **CMake** (vers√£o 3.10 ou superior)
* **make**
* **Python 3** (opcional, para gera√ß√£o de gr√°ficos)

### Instala√ß√£o R√°pida

O projeto possui um `Makefile` simplificado na raiz que **automatiza todo o processo**. Basta executar:

```bash
# 1Ô∏è‚É£ Clone o reposit√≥rio
git clone https://github.com/Jottynha/SO-SimuladorVonNeumann.git
cd SO-SimuladorVonNeumann

# 2Ô∏è‚É£ Configure e compile (cria build/, executa cmake e compila tudo)
make

# 3Ô∏è‚É£ Execute o simulador
make run
```

**Pronto!** üéâ O simulador est√° configurado e rodando.

#### O que acontece no `make`?

```bash
üîß Configurando o projeto...
  üìÅ Criando diret√≥rio build/...
  ‚öôÔ∏è  Executando cmake...
‚úÖ Configura√ß√£o conclu√≠da!

üî® Compilando o projeto...
[  2%] Building CXX object simulador.dir/src/main.cpp.o
[ 40%] Linking CXX executable simulador
[100%] Built target simulador
‚úÖ Compila√ß√£o conclu√≠da!
```

O Makefile automatiza:
1. **Cria√ß√£o do diret√≥rio `build/`**
2. **Execu√ß√£o do `cmake ..`** para gerar Makefiles
3. **Compila√ß√£o com `make -j`** (usa todos os cores)
4. **C√≥pia dos arquivos JSON** (processos e tasks)

---

### Comandos Dispon√≠veis

Execute `make help` para ver todos os comandos:

```bash
make help
```

**Tabela de Comandos:**

| Comando | Descri√ß√£o |
|---------|-----------|
| **Configura√ß√£o e Build** ||
| `make` | üîß Configura e compila o projeto completo (setup + build) |
| `make setup` | üìÅ Cria diret√≥rio `build/` e executa `cmake` |
| `make build` | üî® Compila o simulador e testes |
| `make install-deps` | üì¶ Instala depend√™ncias Python (matplotlib, pandas, etc.) |
| **Execu√ß√£o** ||
| `make run` | üöÄ Executa o simulador principal |
| `make test` | üß™ Executa todos os testes |
| `make check` | ‚úÖ Verifica√ß√£o r√°pida (PASSOU/FALHOU) |
| **An√°lise** ||
| `make plots` | üìä Gera gr√°ficos de an√°lise de desempenho |
| **Limpeza** ||
| `make clean` | üßπ Remove todo o diret√≥rio `build/` |
| `make clean-results` | üóëÔ∏è Remove apenas resultados (.dat, .csv, .png) |
| **Ajuda** ||
| `make help` | ‚ÑπÔ∏è Mostra lista completa de comandos |

---

### Compila√ß√£o Manual (Alternativa)

Se preferir executar os comandos manualmente sem o Makefile wrapper:

```bash
# 1. Criar e acessar diret√≥rio de build
mkdir build
cd build

# 2. Configurar com CMake
cmake ..

# 3. Compilar (usando todos os cores dispon√≠veis)
make -j$(nproc)

# 4. Executar
./simulador
```

---

### Executando o Simulador

Ao executar `make run` (ou `cd build && ./simulador`), voc√™ ver√° o menu interativo:

```
=== SIMULADOR DE ARQUITETURA MULTICORE VON NEUMANN ===

Digite o n√∫mero de cores (1-8): 8
Configura√ß√£o: 8 core(s)
Usar multi-threading? (s/n, padr√£o: s): s
Threading: HABILITADO (execu√ß√£o paralela)

Escolha o algoritmo de escalonamento:
1. FCFS (First-Come, First-Served)
2. SJN (Shortest Job Next)
3. Priority
4. Round Robin (RR)
5. Executar TODOS e Comparar
Digite sua escolha (1-5): 5

Executando FCFS (8 cores, multi-thread)...
[LOAD_PROCESSES] Carregando 9 processos...
Simula√ß√£o conclu√≠da!
Tempo de execu√ß√£o: 12.77 ms

Executando SJN (8 cores, multi-thread)...
Simula√ß√£o conclu√≠da!
Tempo de execu√ß√£o: 13.45 ms

[... continua com Priority e RoundRobin ...]

üìä M√©tricas salvas em: output/metrics_multi.csv
```

**Op√ß√µes de execu√ß√£o:**

* **N√∫mero de cores**: 1 a 8
  - `1 core`: Execu√ß√£o sequencial (baseline)
  - `2-4 cores`: Paralelismo moderado
  - `8 cores`: M√°ximo paralelismo (recomendado para compara√ß√µes)

* **Multi-threading**: 
  - `s` (sim): Usa threads C++ reais (execu√ß√£o paralela verdadeira)
  - `n` (n√£o): Simula√ß√£o sequencial (√∫til para debugging)

* **Escalonador**:
  - `1-4`: Executa um escalonador espec√≠fico
  - `5`: **Recomendado** - Executa todos os 4 escalonadores e gera compara√ß√£o completa

---

### Executando Testes

```bash
# Todos os testes
make test

# Verifica√ß√£o r√°pida
make check

# Testes individuais (a partir do diret√≥rio build/)
cd build
make test_ula      # Teste da ULA
make test_hash     # Teste do mapeamento de registradores
make test_bank     # Teste do banco de registradores
make test_metrics  # Teste de m√©tricas da CPU
```

### Gerando Gr√°ficos de An√°lise

Ap√≥s executar o simulador com a op√ß√£o 5, voc√™ pode gerar gr√°ficos:

```bash
# Instalar depend√™ncias (primeira vez)
make install-deps

# Gerar gr√°ficos
make plots
```

Os gr√°ficos ser√£o salvos em `plots/`:
- Compara√ß√£o de tempos de execu√ß√£o
- Utiliza√ß√£o de CPU por escalonador
- Cache hit rate
- Context switches
- E mais...

### Arquivos de Sa√≠da

O simulador gera v√°rios arquivos de sa√≠da em `build/output/`:

| Arquivo | Conte√∫do |
|---------|----------|
| `resultados_*_multicore.dat` | Logs detalhados de execu√ß√£o por escalonador |
| `comparacao_escalonadores_multicore_*cores.txt` | Tabela comparativa completa |
| `metrics_multi.csv` | M√©tricas agregadas para an√°lise |
| `metrics_comparison_multicore_*.csv` | Compara√ß√£o entre escalonadores |

### Limpeza

```bash
# Limpar tudo (remove build/)
make clean

# Limpar apenas resultados de simula√ß√£o
make clean-results
```

---

## Personaliza√ß√£o e Configura√ß√£o para Testes

<div align="justify">

Esta se√ß√£o descreve **como personalizar o simulador** para realizar experimentos e testes customizados. O sistema foi projetado para ser altamente configur√°vel atrav√©s de arquivos JSON e par√¢metros de c√≥digo.

### [1] Configura√ß√£o de Processos (PCB)

**Localiza√ß√£o:** `processes/process_*.json`

Cada processo √© definido por um arquivo JSON que controla seu comportamento no escalonador.

**Exemplo de Estrutura:**

```json
{
  "pid": 1,
  "name": "Meu Processo Teste",
  "priority": 3,
  "quantum": 10,
  "arrival_time": 0,
  "memWeights": {
    "cache": 1,
    "main": 5,
    "secondary": 10
  }
}
```

**Par√¢metros Configur√°veis:**

| Par√¢metro | Tipo | Descri√ß√£o | Valores Recomendados |
|-----------|------|-----------|----------------------|
| `pid` | int | Identificador √∫nico do processo | 1-99 |
| `name` | string | Nome descritivo do processo | Qualquer string |
| `priority` | int | Prioridade (maior = mais priorit√°rio) | 1-5 (1=alta, 5=baixa) |
| `quantum` | int | Quantum para Round Robin (ciclos) | 5-20 ciclos |
| `arrival_time` | int | Tempo de chegada (ms) | 0 ou mais |
| `memWeights.cache` | int | Custo em ciclos para acesso √† cache | 1 (padr√£o) |
| `memWeights.main` | int | Custo em ciclos para acesso √† RAM | 5-10 |
| `memWeights.secondary` | int | Custo em ciclos para acesso ao swap | 10-100 |

**Como Criar Novos Processos:**

1. Copie um arquivo existente: `cp processes/process_quick.json processes/process_meu_teste.json`
2. Edite os campos conforme necess√°rio
3. Crie o arquivo de tarefas correspondente (veja se√ß√£o 2)
4. Recompile e execute: `cd build && make run`

**Experimentos Sugeridos Pelos Autores:**
- **Teste de Prioridade**: Crie processos com prioridades diferentes (1, 3, 5) e observe o comportamento no escalonador Priority
- **Teste de Quantum**: Varie o quantum (5, 10, 20) e analise o n√∫mero de context switches no Round Robin
- **Teste de Carga de Mem√≥ria**: Ajuste `memWeights` para simular processos memory-intensive vs CPU-intensive

---

### [2] Programa√ß√£o de Tarefas (Assembly MIPS)

**Localiza√ß√£o:** `tasks/tasks_*.json`

Define o **programa em assembly MIPS** que cada processo executar√°.

**Exemplo de Estrutura:**

```json
{
  "program": [
    { "instruction": "li", "rt": "$t0", "immediate": 100 },
    { "instruction": "li", "rt": "$t1", "immediate": 200 },
    { "instruction": "add", "rd": "$t2", "rs": "$t0", "rt": "$t1" },
    { "instruction": "print", "rt": "$t2" },
    { "instruction": "end" }
  ]
}
```

**Instru√ß√µes Suportadas:**

| Instru√ß√£o | Formato | Descri√ß√£o | Exemplo |
|-----------|---------|-----------|---------|
| `li` | Load Immediate | Carrega imediato em registrador | `{ "instruction": "li", "rt": "$t0", "immediate": 42 }` |
| `add` | Soma | Soma dois registradores | `{ "instruction": "add", "rd": "$t0", "rs": "$t1", "rt": "$t2" }` |
| `sub` | Subtra√ß√£o | Subtrai dois registradores | `{ "instruction": "sub", "rd": "$t0", "rs": "$t1", "rt": "$t2" }` |
| `mul` | Multiplica√ß√£o | Multiplica dois registradores | `{ "instruction": "mul", "rd": "$t0", "rs": "$t1", "rt": "$t2" }` |
| `div` | Divis√£o | Divide dois registradores | `{ "instruction": "div", "rd": "$t0", "rs": "$t1", "rt": "$t2" }` |
| `lw` | Load Word | Carrega palavra da mem√≥ria | `{ "instruction": "lw", "rt": "$t0", "rs": "$t1", "immediate": 0 }` |
| `sw` | Store Word | Armazena palavra na mem√≥ria | `{ "instruction": "sw", "rt": "$t0", "rs": "$t1", "immediate": 0 }` |
| `beq` | Branch if Equal | Salto condicional se igual | `{ "instruction": "beq", "rs": "$t0", "rt": "$t1", "label": 10 }` |
| `bne` | Branch if Not Equal | Salto condicional se diferente | `{ "instruction": "bne", "rs": "$t0", "rt": "$t1", "label": 10 }` |
| `j` | Jump | Salto incondicional | `{ "instruction": "j", "label": 5 }` |
| `print` | Print | Imprime valor (I/O) | `{ "instruction": "print", "rt": "$t0" }` |
| `end` | End | Finaliza programa | `{ "instruction": "end" }` |

**Registradores Dispon√≠veis:**

- **Tempor√°rios**: `$t0` a `$t9` (10 registradores)
- **Salvos**: `$s0` a `$s7` (8 registradores)
- **Argumentos**: `$a0` a `$a3` (4 registradores)
- **Resultados**: `$v0` a `$v1` (2 registradores)
- **Zero**: `$zero` (sempre 0, read-only)

**Criando Programas Customizados:**

```bash
# Copiar template
cp tasks/tasks_quick.json tasks/tasks_meu_programa.json
# Editar com seu editor favorito
nano tasks/tasks_meu_programa.json
```

**Exemplos de Programas:**
**a) Loop Simples (10 itera√ß√µes):**
```json
{
  "program": [
    { "instruction": "li", "rt": "$t0", "immediate": 0 },
    { "instruction": "li", "rt": "$t1", "immediate": 10 },
    { "instruction": "add", "rd": "$t0", "rs": "$t0", "immediate": 1 },
    { "instruction": "bne", "rs": "$t0", "rt": "$t1", "label": 2 },
    { "instruction": "end" }
  ]
}
```
**b) Acesso Intensivo √† Mem√≥ria:**
```json
{
  "program": [
    { "instruction": "li", "rt": "$t0", "immediate": 100 },
    { "instruction": "sw", "rt": "$t0", "rs": "$zero", "immediate": 0 },
    { "instruction": "lw", "rt": "$t1", "rs": "$zero", "immediate": 0 },
    { "instruction": "sw", "rt": "$t1", "rs": "$zero", "immediate": 4 },
    { "instruction": "lw", "rt": "$t2", "rs": "$zero", "immediate": 4 },
    { "instruction": "end" }
  ]
}
```
**c) Opera√ß√µes Aritm√©ticas Intensivas (CPU-Bound):**
```json
{
  "program": [
    { "instruction": "li", "rt": "$t0", "immediate": 1000 },
    { "instruction": "li", "rt": "$t1", "immediate": 500 },
    { "instruction": "add", "rd": "$t2", "rs": "$t0", "rt": "$t1" },
    { "instruction": "mul", "rd": "$t3", "rs": "$t2", "rt": "$t0" },
    { "instruction": "div", "rd": "$t4", "rs": "$t3", "rt": "$t1" },
    { "instruction": "sub", "rd": "$t5", "rs": "$t4", "rt": "$t0" },
    { "instruction": "end" }
  ]
}
```
---

### [3] Configura√ß√£o do Sistema (src/main.cpp)

**Localiza√ß√£o:** `src/main.cpp`

Par√¢metros globais do sistema podem ser alterados diretamente no c√≥digo-fonte.

**Par√¢metros Principais:**

```cpp
// Linha ~50-70: Configura√ß√£o do sistema
const int NUM_CORES = 4;              // N√∫mero de cores (1-8)
const int CACHE_SIZE = 256;           // Tamanho da cache em blocos (64-1024)
const int SNAPSHOT_INTERVAL = 10;     // Intervalo de snapshots em ciclos (5-50)
// Linha ~100-120: Configura√ß√£o de mem√≥ria
const size_t RAM_SIZE = 4096;         // Tamanho da RAM em blocos (1024-8192)
const int CACHE_HIT_LATENCY = 1;      // Lat√™ncia da cache em ciclos (1)
const int RAM_LATENCY = 5;            // Lat√™ncia da RAM em ciclos (5-10)
const int SWAP_LATENCY = 10;          // Lat√™ncia do swap em ciclos (10-100)
// Linha ~150-170: Configura√ß√£o de escalonamento
SchedulingPolicy policy = ROUND_ROBIN;  // FCFS, SJN, PRIORITY, ROUND_ROBIN
const int DEFAULT_QUANTUM = 5;        // Quantum padr√£o para RR (5-20)
```

**Como Alterar:**

1. Abra o arquivo: `nano src/main.cpp`
2. Localize a se√ß√£o de configura√ß√£o (busque por "CONFIG" ou os valores acima)
3. Modifique os valores conforme necess√°rio
4. Recompile: `cd build && cmake .. && make`
5. Execute: `./simulador`

**Experimentos Recomendados:**

| Par√¢metro | Teste | Objetivo |
|-----------|-------|----------|
| `NUM_CORES` | Variar 1, 2, 4, 8 | An√°lise de speedup multicore |
| `CACHE_SIZE` | Variar 64, 128, 256, 512 | Impacto do tamanho da cache na taxa de hit |
| `DEFAULT_QUANTUM` | Variar 5, 10, 20 | Overhead de context switch vs interatividade |
| `RAM_LATENCY` | Variar 5, 10, 20 | Impacto da lat√™ncia de mem√≥ria no desempenho |

---

### [4] Pol√≠ticas de Escalonamento (src/cpu/Scheduler.cpp)

**Localiza√ß√£o:** `src/cpu/Scheduler.cpp`

**Como Alternar Entre Pol√≠ticas:**

**Op√ß√£o 1: Via C√≥digo (src/main.cpp)**

```cpp
// Linha ~160
// Altere o enum para a pol√≠tica desejada:
SchedulingPolicy policy = FCFS;          // First-Come, First-Served
// SchedulingPolicy policy = SJN;        // Shortest Job Next
// SchedulingPolicy policy = PRIORITY;   // Baseado em prioridade
// SchedulingPolicy policy = ROUND_ROBIN; // Round Robin (preemptivo)
```

**Op√ß√£o 2: Via Interface do Simulador**

Quando executar o simulador, voc√™ ver√° um menu:

```
Selecione a pol√≠tica de escalonamento:
1. FCFS (First-Come, First-Served)
2. SJN (Shortest Job Next)
3. Priority (Baseado em Prioridade)
4. Round Robin (Preemptivo)
Escolha (1-4): _
```

**Modificando Algoritmos de Escalonamento:**

Para criar uma **nova pol√≠tica de escalonamento customizada**:

1. Abra `src/cpu/Scheduler.cpp`
2. Adicione um novo m√©todo:

```cpp
// Adicione ap√≥s linha ~200
PCB* Scheduler::select_process_CUSTOM() {
    if (ready_queue.empty()) return nullptr;
    
    // Seu algoritmo customizado aqui
    // Exemplo: seleciona processo com menor PID
    PCB* selected = ready_queue[0];
    for (auto* process : ready_queue) {
        if (process->pid < selected->pid) {
            selected = process;
        }
    }
    
    // Remove da fila e retorna
    ready_queue.erase(
        std::remove(ready_queue.begin(), ready_queue.end(), selected),
        ready_queue.end()
    );
    
    return selected;
}
```

3. Adicione no enum (em `Scheduler.hpp`):

```cpp
enum SchedulingPolicy {
    FCFS,
    SJN,
    PRIORITY,
    ROUND_ROBIN,
    CUSTOM        // Sua nova pol√≠tica
};
```

4. Integre no dispatcher (em `Scheduler.cpp`, m√©todo `select_process`):

```cpp
PCB* Scheduler::select_process() {
    switch (policy) {
        case FCFS:        return select_process_FCFS();
        case SJN:         return select_process_SJN();
        case PRIORITY:    return select_process_Priority();
        case ROUND_ROBIN: return select_process_RoundRobin();
        case CUSTOM:      return select_process_CUSTOM();  // Nova linha
        default:          return nullptr;
    }
}
```

---

### [5] Pol√≠ticas de Cache (src/memory/cachePolicy.cpp)

**Localiza√ß√£o:** `src/memory/cachePolicy.cpp` e `src/memory/Cache.cpp`

**Como Alternar Entre FIFO e LRU:**

```cpp
// Em src/main.cpp, linha ~110
Cache cache(CACHE_SIZE, ReplacementPolicy::FIFO);  // FIFO
// Cache cache(CACHE_SIZE, ReplacementPolicy::LRU); // LRU
```

**Implementando Nova Pol√≠tica de Substitui√ß√£o:**

Exemplo: **Pol√≠tica RANDOM (aleat√≥ria)**

1. Adicione no enum (`src/memory/cachePolicy.hpp`):

```cpp
enum class ReplacementPolicy {
    FIFO,
    LRU,
    RANDOM    // Nova pol√≠tica
};
```

2. Implemente o algoritmo (`src/memory/cachePolicy.cpp`):

```cpp
size_t CachePolicy::getAddressToReplace_RANDOM(
    const std::unordered_map<size_t, CacheEntry>& cache_data
) {
    if (cache_data.empty()) return -1;
    
    // Gera √≠ndice aleat√≥rio
    size_t random_index = rand() % cache_data.size();
    
    // Itera at√© o √≠ndice aleat√≥rio
    auto it = cache_data.begin();
    std::advance(it, random_index);
    
    return it->first;  // Retorna endere√ßo aleat√≥rio
}
```

3. Integre na classe Cache (`src/memory/Cache.cpp`):

```cpp
void Cache::put(size_t address, size_t data, MemoryManager* memManager) {
    if (cache_data.size() >= capacity) {
        size_t victim_addr;
        
        switch (policy) {
            case ReplacementPolicy::FIFO:
                victim_addr = cachePolicy.getAddressToReplace(fifo_queue);
                break;
            case ReplacementPolicy::LRU:
                victim_addr = cachePolicy.getAddressToReplace_LRU(lru_list);
                break;
            case ReplacementPolicy::RANDOM:
                victim_addr = cachePolicy.getAddressToReplace_RANDOM(cache_data);
                break;
        }
        
        // Remove v√≠tima...
    }
}
```

---

### [6] Hierarquia de Mem√≥ria (src/memory/)

**Localiza√ß√£o:** `src/memory/MAIN_MEMORY.cpp`, `SECONDARY_MEMORY.cpp`

**Alterando Tamanhos de Mem√≥ria:**

```cpp
// Em src/memory/MAIN_MEMORY.hpp, linha ~15
#define MAX_MEMORY_SIZE 4096        // RAM: 4096 blocos √ó 4 bytes = 16 KB
#define MEMORY_ACCESS_ERROR 0xDEADBEEF

// Em src/memory/SECONDARY_MEMORY.hpp, linha ~15
#define MAX_SECONDARY_MEMORY_SIZE 1000000  // Swap: ~4 MB
```

**Experimento: Simular Sistemas com Pouca Mem√≥ria**

Reduza os valores para for√ßar mais swaps:

```cpp
#define MAX_MEMORY_SIZE 1024        // Apenas 4 KB de RAM
#define MAX_SECONDARY_MEMORY_SIZE 10000  // Swap limitado
```

Recompile e observe o aumento de acessos ao swap nos relat√≥rios.

---

### [7] Ajustando Lat√™ncias de Mem√≥ria

**Localiza√ß√£o:** `src/memory/MemoryManager.cpp`

```cpp
// Linha ~50-70
const int CACHE_LATENCY = 1;      // Ciclos para acesso √† cache
const int RAM_LATENCY = 5;        // Ciclos para acesso √† RAM
const int SWAP_LATENCY = 10;      // Ciclos para acesso ao swap

// No m√©todo de acesso:
uint32_t MemoryManager::read(uint32_t address, PCB& process) {
    // Tenta cache primeiro
    uint32_t value = cache.get(address);
    if (value != CACHE_MISS) {
        process.memory_cycles += CACHE_LATENCY;  // <-- Altere aqui
        process.cache_hits++;
        return value;
    }
    
    // Cache miss: tenta RAM
    value = ram.ReadMem(address);
    if (value != MEMORY_ACCESS_ERROR) {
        process.memory_cycles += RAM_LATENCY;    // <-- Altere aqui
        cache.put(address, value, this);
        return value;
    }
    
    // RAM miss: vai para swap
    value = swap.ReadMem(address);
    process.memory_cycles += SWAP_LATENCY;       // <-- Altere aqui
    return value;
}
```

**Experimento Sugerido:**

Simule um sistema com mem√≥ria lenta:
- `CACHE_LATENCY = 1`
- `RAM_LATENCY = 20` (4x mais lento)
- `SWAP_LATENCY = 100` (10x mais lento)

Observe como isso afeta o tempo total de execu√ß√£o dos processos.

---

### [8] Snapshots de Mem√≥ria (Intervalo de Captura)

**Localiza√ß√£o:** `src/cpu/CONTROL_UNIT.cpp`

```cpp
// Linha ~400
const int SNAPSHOT_INTERVAL = 10;  // Captura a cada 10 ciclos

// No loop de execu√ß√£o:
snapshot_counter++;
if (snapshot_counter >= SNAPSHOT_INTERVAL) {  // <-- Altere SNAPSHOT_INTERVAL
    MemoryUsageTracker::recordSnapshot(process, cache_usage, ram_usage);
    snapshot_counter = 0;
}
```

**Granularidade Recomendada:**

| Intervalo | Uso | Overhead | Detalhamento |
|-----------|-----|----------|--------------|
| 1 ciclo | Debug detalhado | Alto | M√°ximo |
| 5 ciclos | An√°lise fina | M√©dio | Alto |
| 10 ciclos | **Padr√£o** (recomendado) | Baixo | Bom |
| 20 ciclos | An√°lise geral | Muito baixo | Moderado |
| 50 ciclos | Overview | M√≠nimo | Baixo |

---

### [9] Gerando Relat√≥rios Customizados

**Localiza√ß√£o:** `src/memory/MemoryUsageTracker.cpp`

**Adicionando Novas M√©tricas aos Relat√≥rios:**

Exemplo: adicionar "Taxa de Swap" ao relat√≥rio agregado:

```cpp
// Em MemoryUsageTracker::generateAggregatedReport, linha ~150
void MemoryUsageTracker::generateAggregatedReport(...) {
    // ...existing code...
    
    // Adicione ap√≥s linha de cache hit rate m√©dia:
    uint64_t total_swap_accesses = 0;
    uint64_t total_accesses = 0;
    
    for (const auto& process : processes) {
        total_swap_accesses += process->secondary_mem_accesses;
        total_accesses += process->total_memory_accesses;
    }
    
    double swap_rate = (total_accesses > 0) 
        ? (static_cast<double>(total_swap_accesses) / total_accesses) * 100.0 
        : 0.0;
    
    report << "Taxa de swap media: " << swap_rate << "%\n";
    
    // ...existing code...
}
```

---

### [10] Visualiza√ß√£o de Dados (scripts Python)

**Localiza√ß√£o:** `scripts/`

**Personalizando Gr√°ficos:**

**a) Adicionar novo tipo de gr√°fico (`scripts/plot_results.py`):**

```python
# Adicione ap√≥s linha ~180
def plot_custom_metric(data):
    """Plota m√©trica customizada"""
    import matplotlib.pyplot as plt
    fig, ax = plt.subplots(figsize=(10, 6))
    # Exemplo: gr√°fico de dispers√£o PID vs Cache Hit Rate
    pids = [p['pid'] for p in data]
    hit_rates = [p['cache_hit_rate'] for p in data]
    ax.scatter(pids, hit_rates, s=100, alpha=0.6)
    ax.set_xlabel('Process ID')
    ax.set_ylabel('Cache Hit Rate (%)')
    ax.set_title('Cache Hit Rate por Processo')
    ax.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('../plots/custom_metric.png', dpi=300)
    plt.close()
    print("Gr√°fico customizado gerado: custom_metric.png")
# Chame a fun√ß√£o no main:
if __name__ == '__main__':
    data = load_data()
    plot_custom_metric(data)
```

**b) Modificar cores e estilos:**

```python
# Em qualquer script, modifique paletas de cores:
import matplotlib.pyplot as plt

# Paleta padr√£o
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']

# Paleta customizada (ex: tons de azul)
colors = ['#1E3A8A', '#3B82F6', '#60A5FA', '#93C5FD']

# Use em seus plots:
ax.bar(x, y, color=colors)
```

**c) Gerar todos os gr√°ficos de uma vez:**

```bash
# No diret√≥rio raiz do projeto
cd build
make plots

# Ou diretamente:
python3 ../scripts/plot_results.py
python3 ../scripts/plot_memory.py
python3 ../scripts/compare_schedulers.py
```

---

### Dicas Importantes

1. **Sempre recompile ap√≥s altera√ß√µes:** `cd build && make`
2. **Fa√ßa backup dos resultados:** `cp -r build/output/ resultados_experimento_X/`
3. **Use Git para versionar configura√ß√µes:** `git commit -am "Experimento: 8 cores"`
4. **Documente seus testes:** Crie um arquivo `EXPERIMENTOS.md` com suas observa√ß√µes
5. **Valide resultados:** Execute m√∫ltiplas vezes para garantir reprodutibilidade

</div>

---

## Colaboradores

### EQUIPE CPU:
#### Elabora√ß√£o da Unidade de Controle:
- Jo√£o Pedro Rodrigues Silva ([jottynha](https://github.com/Jottynha))
- Pedro Augusto Gontijo Moura ([PedroAugusto08](https://github.com/PedroAugusto08))

#### Elabora√ß√£o dos registradores:
- Anderson Rodrigues dos Santos ([anderrsantos](https://github.com/anderrsantos)) 

#### Elabora√ß√£o do banco de registradores:
- Eduardo da Silva Torres Grillo ([EduardoGrillo](https://github.com/EduardoGrillo))

#### Elabora√ß√£o da hash register:
- √Ålvaro Augusto Jos√© Silva ([alvaroajs](https://github.com/alvaroajs))
- Henrique de Freitas Ara√∫jo ([ak4ai](https://github.com/ak4ai)) 

#### Elabora√ß√£o da ULA:
- Jader Oliveira Silva ([0livas](https://github.com/0livas))

### EQUIPE MEM√ìRIAS:
#### Elabora√ß√£o das Mem√≥rias Prim√°ria, Secund√°ria e Cache:
- Guilherme Alvarenga de Azevedo ([alvarengazv](https://github.com/alvarengazv))
- Jo√£o Paulo da Cunha Faria ([joaopaulocunhafaria](https://github.com/0livjoaopaulocunhafariaas))
- Joaquim Cezar Santana da Cruz ([JoaquimCruz](https://github.com/JoaquimCruz))
- Lucas Cerqueira Portela ([lucasporteladev](https://github.com/lucasporteladev))

#### Documenta√ß√£o das Mem√≥rias:
- Maria Eduarda Teixeira Souza ([dudatsouza](https://github.com/dudatsouza))
- √âlcio Costa Amorim Neto ([elcioam](https://github.com/elcioam))

### EQUIPE PERIF√âRICOS:
#### Elabora√ß√£o do programa e parser JSON:
- ‚Å†Eduardo Henrique Queiroz Almeida ([edualmeidahr](https://github.com/edualmeidahr))
- ‚Å†Jo√£o Francisco Teles da Silva ([joaofranciscoteles](https://github.com/joaofranciscoteles))
- ‚Å†Ma√≠ra Beatriz de Almeida Lacerda ([mairaallacerda](https://github.com/mairaallacerda))

#### Elabora√ß√£o do I/O:
- Bruno Prado dos Santos ([bybrun0](https://github.com/bybrun0))
- ‚Å†S√©rgio Henrique Quedas Ramos ([serginnn](https://github.com/serginnn))

### EQUIPE SUPORTE:
#### Configura√ß√£o do Docker e apoio √† integra√ß√µes na CPU:
- Gabriel Vitor Silva ([gvs22](https://github.com/gvs22))
- Rafael Adolfo Silva Ferreira ([radsfer](https://github.com/radsfer))
- Rafael Henrique Reis Costa ([RafaelReisyzx](https://github.com/RafaelReisyzx))

#### Documenta√ß√£o geral e apoio √† integra√ß√£o das mem√≥rias:
- L√≠via Gon√ßalves ([livia-goncalves-01](https://github.com/livia-goncalves-01))
- Samuel Silva Gomes ([samuelsilvg](https://github.com/samuelsilvg))

#### Integra√ß√µes e suporte aos perif√©ricos:
- Deivy Rossi Teixeira de Melo ([deivyrossi](https://github.com/deivyrossi))
- Matheus Emanuel da Silva ([matheus-emanue123](https://github.com/matheus-emanue123))

# Simulador Multicore Von Neumann

**Disciplina:** Sistemas Operacionais  
**Institui√ß√£o:** Centro Federal de Educa√ß√£o Tecnol√≥gica de Minas Gerais (CEFET-MG), Divin√≥polis  
**Projeto:** Trabalho Final - Simula√ß√£o de Arquitetura Multicore com Gerenciamento de Mem√≥ria e Escalonamento  

---

## Sobre o Projeto

Este projeto implementa um **simulador completo de arquitetura multicore Von Neumann** conforme especificado no enunciado do trabalho final. O sistema representa uma arquitetura com **m√∫ltiplos n√∫cleos de processamento** que compartilham uma **mem√≥ria principal unificada**, executando um lote inicial de programas sob diferentes pol√≠ticas de escalonamento e gerenciamento de mem√≥ria.

### Conformidade com o Enunciado

O simulador atende **100% dos requisitos t√©cnicos** especificados:

- **Arquitetura Multicore**: 1-8 n√∫cleos configur√°veis com execu√ß√£o paralela real
- **Lote Inicial de Programas**: 9 processos carregados do disco antes da execu√ß√£o
- **Mem√≥ria Compartilhada Unificada**: Acesso sincronizado entre todos os cores
- **Mapeamento Tanenbaum**: Segmenta√ß√£o com 4 segmentos (CODE, DATA, STACK, HEAP)
- **Pol√≠ticas de Substitui√ß√£o**: FIFO e LRU completamente implementadas
- **4 Pol√≠ticas de Escalonamento**: FCFS, SJN, Priority, Round Robin
- **Cen√°rio N√£o-Preemptivo**: FCFS, SJN e Priority executam at√© conclus√£o
- **Cen√°rio Preemptivo**: Round Robin com quantum configur√°vel
- **M√©tricas Completas**: Tempo de espera, retorno, utiliza√ß√£o, throughput
- **Relat√≥rios de Escalonamento**: Compara√ß√£o detalhada entre pol√≠ticas
- **Utiliza√ß√£o de Mem√≥ria ao Longo do Tempo**: Snapshots autom√°ticos e relat√≥rios

### Componentes Implementados

| Componente | Descri√ß√£o |
|------------|-----------|
| Pipeline MIPS | 5 est√°gios (Fetch ‚Üí Decode ‚Üí Execute ‚Üí Memory ‚Üí WriteBack) |
| Multicore | 1-8 cores com threads C++ e sincroniza√ß√£o |
| Escalonamento | 4 pol√≠ticas (FCFS, SJN, Priority, RR) |
| Mem√≥ria Segmentada | Modelo Tanenbaum com 4 segmentos |
| Cache FIFO/LRU | Pol√≠ticas de substitui√ß√£o implementadas |
| Hierarquia Mem√≥ria | 3 n√≠veis (Cache ‚Üí RAM ‚Üí Swap) |
| Rastreamento Temporal | Snapshots a cada 10 ciclos |
| Relat√≥rios | Individuais e agregados do sistema |
| Visualiza√ß√£o | 12 gr√°ficos comparativos (Python/matplotlib) |

---

## Caracter√≠sticas Implementadas

### Arquitetura Von Neumann Multicore

#### Pipeline MIPS de 5 Est√°gios
O simulador implementa um pipeline completo conforme arquitetura MIPS:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FETCH  ‚îÇ -> ‚îÇ DECODE ‚îÇ -> ‚îÇEXECUTE ‚îÇ -> ‚îÇ MEMORY ‚îÇ -> ‚îÇWRITEBACK‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   IF            ID             EX            MEM            WB
```

**Est√°gios:**
1. **Fetch (IF)**: Busca instru√ß√£o da mem√≥ria usando PC (Program Counter)
2. **Decode (ID)**: Decodifica instru√ß√£o e l√™ registradores
3. **Execute (EX)**: Executa opera√ß√£o aritm√©tica/l√≥gica na ULA
4. **Memory (MEM)**: Acessa mem√≥ria para load/store
5. **WriteBack (WB)**: Escreve resultado no banco de registradores

#### Configura√ß√£o Multicore
- **Cores**: 1 a 8 n√∫cleos configur√°veis pelo usu√°rio
- **Threads**: Cada core executa em thread C++ separada
- **Sincroniza√ß√£o**: Mutexes para acesso √† mem√≥ria compartilhada
- **M√©tricas**: Utiliza√ß√£o individual por core

**Caracter√≠sticas:**
- Mem√≥ria principal unificada e compartilhada
- Escalonamento distribu√≠do entre cores
- Sincroniza√ß√£o sem condi√ß√£o de corrida
- An√°lise de speedup multicore vs single-core

### Pol√≠ticas de Escalonamento

Conforme especificado no enunciado, o simulador implementa **4 pol√≠ticas de escalonamento** com suporte a cen√°rios preemptivos e n√£o-preemptivos:

| Pol√≠tica | Tipo | Descri√ß√£o | Cen√°rio |
|----------|------|-----------|---------|
| **FCFS** | N√£o-preemptivo | First-Come, First-Served - ordem de chegada | Executa at√© conclus√£o |
| **SJN** | N√£o-preemptivo | Shortest Job Next - menor tempo estimado primeiro | Executa at√© conclus√£o |
| **Priority** | N√£o-preemptivo | Baseado em prioridades (1-5), maior prioridade primeiro | Executa at√© conclus√£o |
| **Round Robin** | **Preemptivo** | Quantum de tempo (5 ciclos) com rod√≠zio circular | **Interrupt√≠vel por quantum** |

#### Cen√°rio N√£o-Preemptivo (FCFS, SJN, Priority)
- Processos executam **at√© a conclus√£o** sem interrup√ß√µes
- Ordem determinada pelo escalonador no in√≠cio
- Ideal para demonstrar diferentes estrat√©gias de ordena√ß√£o

#### Cen√°rio Preemptivo (Round Robin)
- Processos **interrupt√≠veis** ap√≥s quantum (5 ciclos de pipeline)
- **Context switch** autom√°tico ao expirar quantum
- Estado do processo salvo (PC, registradores, m√©tricas)
- Recoloca√ß√£o na fila Ready para retomada posterior
- **Simula√ß√£o de cache pollution** durante troca de contexto

**Implementa√ß√£o de Preemp√ß√£o:**
```cpp
// CONTROL_UNIT.cpp - linha 469
if (clock >= process.quantum) {
    context.endExecution = true;  // Marca para preemp√ß√£o
}

// main.cpp - linha 350-357
if (current_process->state == State::Ready) {
    // Processo n√£o terminou, recoloca na fila
    scheduler.add_process(current_process);
    memManager.simulateContextSwitch(); // Cache pollution
    scheduler.increment_context_switch();
}
```

### Gerenciamento de Mem√≥ria (Modelo Tanenbaum)

O simulador implementa um sistema completo de gerenciamento de mem√≥ria conforme especificado no enunciado, baseado no modelo de Tanenbaum.

#### Hierarquia de Mem√≥ria (3 N√≠veis)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CPU CORES                         ‚îÇ
‚îÇ                 (1-8 n√∫cleos)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Cache L1   ‚îÇ  ‚óÑ‚îÄ‚îÄ FIFO ou LRU
              ‚îÇ  256 blocos ‚îÇ      (substitui√ß√£o)
              ‚îÇ   4 bytes   ‚îÇ
              ‚îÇ   = 1 KB    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ miss
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  RAM        ‚îÇ  ‚óÑ‚îÄ‚îÄ Mem√≥ria principal
              ‚îÇ 4096 blocos ‚îÇ      compartilhada
              ‚îÇ  4 bytes    ‚îÇ
              ‚îÇ  = 16 KB    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ swap
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ Disco/Swap  ‚îÇ  ‚óÑ‚îÄ‚îÄ Mem√≥ria secund√°ria
              ‚îÇ  Ilimitado  ‚îÇ      (virtual)
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Especifica√ß√µes:**
- **Cache L1**: 256 blocos √ó 4 bytes = 1 KB (por core)
- **RAM**: 4096 blocos √ó 4 bytes = 16 KB (compartilhada)
- **Swap**: Capacidade ilimitada (simula√ß√£o de disco)

**Lat√™ncias:**
- Cache hit: 1 ciclo
- RAM: 5 ciclos
- Swap: 10 ciclos

#### Segmenta√ß√£o de Mem√≥ria (Modelo Tanenbaum)

Implementa√ß√£o completa do modelo de segmenta√ß√£o conforme Tanenbaum, com 4 segmentos:

| Segmento | ID Bin√°rio | Descri√ß√£o | Base | Limite | Prote√ß√£o |
|----------|------------|-----------|------|--------|----------|
| **CODE** | `00` | C√≥digo do programa (instru√ß√µes) | Din√¢mico | Por processo | **Read-Only** |
| **DATA** | `01` | Vari√°veis globais e est√°ticas | Din√¢mico | Por processo | Read-Write |
| **STACK** | `10` | Pilha de execu√ß√£o (chamadas) | Din√¢mico | Por processo | Read-Write |
| **HEAP** | `11` | Aloca√ß√£o din√¢mica de mem√≥ria | Din√¢mico | Por processo | Read-Write |

**Formato de Endere√ßo L√≥gico (32 bits):**
```
 31  30 | 29                                    0
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Seg ID ‚îÇ           Offset                     ‚îÇ
‚îÇ2 bits  ‚îÇ          30 bits                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Exemplos:
0x00000064 = 00|000064 ‚Üí CODE, offset 100 (instru√ß√£o no endere√ßo 100)
0x40000100 = 01|000100 ‚Üí DATA, offset 256 (vari√°vel global)
0x80000050 = 10|000050 ‚Üí STACK, offset 80 (frame de fun√ß√£o)
0xC0000200 = 11|000200 ‚Üí HEAP, offset 512 (malloc)
```

**Tradu√ß√£o de Endere√ßo:**
```
Endere√ßo L√≥gico ‚Üí [Tabela de Segmentos] ‚Üí Endere√ßo F√≠sico

1. Extrair Segmento (bits 31-30)
2. Extrair Offset (bits 29-0)
3. Verificar limites: offset < segment.limit
4. Verificar prote√ß√£o: read-only vs read-write
5. Calcular f√≠sico: segment.base + offset
```

**Implementa√ß√£o (`src/memory/SegmentTable.hpp`):**
```cpp
class SegmentTable {
    struct Segment {
        uint32_t base;      // Endere√ßo base f√≠sico
        uint32_t limit;     // Tamanho do segmento
        bool present;       // Segmento carregado?
        bool read_only;     // Prote√ß√£o de escrita
    };
    
    Segment segments[4];  // CODE, DATA, STACK, HEAP
    
    uint32_t translate(uint8_t segment_id, uint32_t offset);
    bool checkProtection(uint8_t segment_id, bool is_write);
};

class SegmentedAddressing {
    // Codificar: segmento + offset ‚Üí endere√ßo l√≥gico 32 bits
    uint32_t encodeAddress(uint8_t segment_id, uint32_t offset);
    
    // Decodificar: endere√ßo l√≥gico ‚Üí (segmento, offset)
    std::pair<uint8_t, uint32_t> decodeAddress(uint32_t logical_addr);
};
```

#### Pol√≠ticas de Substitui√ß√£o de Cache

O simulador implementa **duas pol√≠ticas** de substitui√ß√£o de blocos na cache, conforme especificado:

##### 1. FIFO (First In, First Out)
- Substitui o **bloco mais antigo** (primeiro a entrar)
- Simples e previs√≠vel
- N√£o considera padr√£o de acesso

##### 2. LRU (Least Recently Used) 
- Substitui o **bloco menos recentemente usado**
- Mant√©m blocos "quentes" (frequentemente acessados)
- Implementa√ß√£o com lista ordenada de acesso

**Implementa√ß√£o (`src/memory/cachePolicy.hpp`):**
```cpp
enum class ReplacementPolicy {
    FIFO,  // First In, First Out
    LRU    // Least Recently Used (implementado)
};

class CachePolicy {
    // FIFO: retorna endere√ßo mais antigo
    size_t getAddressToReplace();
    
    // LRU: retorna endere√ßo menos recentemente usado
    size_t getAddressToReplaceLRU(std::list<size_t>& lru_list);
    
    // Atualiza lista LRU ap√≥s acesso
    void updateLRU(std::list<size_t>& lru_list, size_t address);
};

class Cache {
    ReplacementPolicy policy;     // FIFO ou LRU
    std::list<size_t> lru_list;   // Lista de acesso para LRU
    
    // Alternar pol√≠tica dinamicamente
    void setPolicy(ReplacementPolicy new_policy);
};
```

**Compara√ß√£o:**
| M√©trica | FIFO | LRU |
|---------|------|-----|
| Complexidade | O(1) | O(n) |
| Taxa de Hit | ~13% | ~13-15% |
| Overhead | Baixo | M√©dio |
| Uso | Baseline | Produ√ß√£o |

#### Rastreamento Temporal de Mem√≥ria

Conforme requisito do enunciado: **"utiliza√ß√£o de mem√≥ria ao longo do tempo"**

**Snapshots Autom√°ticos:**
- Capturados **a cada 10 ciclos de pipeline**
- Snapshot inicial (ciclo 0)
- Snapshots peri√≥dicos durante execu√ß√£o
- Snapshot final (t√©rmino do processo)

**Estrutura de Snapshot (`src/cpu/PCB.hpp`):**
```cpp
struct MemorySnapshot {
    int64_t timestamp_ms;      // Momento da captura
    uint64_t cache_usage;      // Bytes usados na cache
    uint64_t ram_usage;        // Bytes usados na RAM
    uint64_t total_accesses;   // Total de acessos at√© agora
    double cache_hit_rate;     // Taxa de hit (%)
};

struct PCB {
    // ... outros campos
    std::vector<MemorySnapshot> memory_usage_timeline;
};
```

**Implementa√ß√£o (`src/memory/MemoryUsageTracker.hpp`):**
```cpp
class MemoryUsageTracker {
public:
    // Captura snapshot do processo
    static void recordSnapshot(PCB& process, 
                              uint64_t cache_usage, 
                              uint64_t ram_usage);
    
    // Gera relat√≥rio individual do processo
    static void generateReport(const PCB& process, 
                              const std::string& output_dir);
    
    // Gera relat√≥rio agregado de todos os processos
    static void generateAggregatedReport(
        const std::vector<std::unique_ptr<PCB>>& processes,
        const std::string& output_file);
};
```

**Integra√ß√£o no Pipeline (`src/cpu/CONTROL_UNIT.cpp`):**
```cpp
void* Core(MemoryManager& memManager, PCB& process, ...) {
    const int SNAPSHOT_INTERVAL = 10;
    int snapshot_counter = 0;
    
    // Snapshot inicial
    MemoryUsageTracker::recordSnapshot(process, 0, 0);
    
    while (context.counterForEnd > 0) {
        // ... execu√ß√£o do pipeline
        
        snapshot_counter++;
        if (snapshot_counter >= SNAPSHOT_INTERVAL) {
            uint64_t cache_usage = (process.cache_hits + process.cache_misses) * 4;
            uint64_t ram_usage = process.primary_mem_accesses * 4;
            MemoryUsageTracker::recordSnapshot(process, cache_usage, ram_usage);
            snapshot_counter = 0;
        }
    }
    
    // Snapshot final
    MemoryUsageTracker::recordSnapshot(process, final_cache, final_ram);
}
```

**Relat√≥rios Gerados:**

1. **Individuais** (9 arquivos): `memory_usage_<nome>_<pid>.txt`
```
========================================
  RELATORIO DE UTILIZACAO DE MEMORIA  
  Processo: Quick Process (PID: 1)
========================================

Tempo(ms)      Cache(bytes)     RAM(bytes)    Total Acess      Cache Hit(%)
---------------------------------------------------------------------------
1700000001              0              0              0              0.00
1700000015            128             40             10             20.00
1700000029            256             40             15             26.67

=== ESTATISTICAS FINAIS ===
Total de snapshots: 3
Memoria cache maxima: 256 bytes
Memoria RAM maxima: 40 bytes
Taxa de cache final: 26.67%
```

2. **Agregado**: `memory_aggregated_report.txt`
```
========================================
RELATORIO AGREGADO DE UTILIZACAO DE MEMORIA
========================================

Total de processos: 9
Periodo de analise: 1700000001 a 1700000150

=== ESTATISTICAS GLOBAIS ===
Cache maxima utilizada: 504 bytes
RAM maxima utilizada: 360 bytes
Taxa de cache hit media: 13.16%

=== RESUMO POR PROCESSO ===
PID  Nome                    Cache Max  RAM Max  Hit Rate
----------------------------------------------------------------
1    Quick Process              128        40      20.00%
2    Short Process              256        80      25.00%
...
9    Loop-Heavy Process         504       360       5.49%
```

### M√©tricas de Desempenho

Conforme especificado no enunciado do trabalho, o simulador coleta e reporta **todas as m√©tricas** necess√°rias para an√°lise comparativa entre pol√≠ticas de escalonamento:

#### M√©tricas de Tempo (por processo)
- **Tempo de Espera** (Wait Time): `start_time - arrival_time`
- **Tempo de Resposta** (Response Time): `start_time - arrival_time`
- **Tempo de Retorno** (Turnaround Time): `finish_time - arrival_time`

#### M√©tricas de Sistema (agregadas)
- **Utiliza√ß√£o M√©dia da CPU**: Percentual de tempo de CPU ocupado
- **Efici√™ncia por N√∫cleo**: Utiliza√ß√£o individual de cada core (multicore)
- **Throughput**: Processos completados por segundo
- **Context Switches**: N√∫mero de trocas de contexto (preemp√ß√£o)

#### M√©tricas de Mem√≥ria
- **Taxa de Cache Hit**: `(hits / total_accesses) * 100`
- **Ciclos de Mem√≥ria**: Tempo gasto em acessos √† hierarquia
- **Acessos por N√≠vel**: Cache L1, RAM, Swap
- **Utiliza√ß√£o Temporal**: Evolu√ß√£o do uso de mem√≥ria ao longo do tempo

#### Exemplo de Relat√≥rio

```
--- METRICAS FINAIS DO PROCESSO 1 ---
Nome do Processo:       Quick Process
Estado Final:           Finished
Prioridade:             1
Quantum:                5

--- METRICAS DE TEMPO ---
Tempo de Espera:        0 ms
Tempo de Resposta:      0 ms
Tempo de Retorno:       12 ms

--- METRICAS DE CPU E MEMORIA ---
Ciclos de Pipeline:     9
Total de Acessos a Mem: 15
  - Leituras:             10
  - Escritas:             5
Acessos a Cache L1:     5
Acessos a Mem Principal:10
Acessos a Mem Secundaria:0
Ciclos Totais de Memoria: 55
Cache Hits:             3
Cache Misses:           12
Ciclos de IO:           1

--- UTILIZACAO DE MEMORIA ---
Snapshots registrados:  2
Taxa de cache final:    20.00%
```

### Processos de Teste (Lote Inicial)

Conforme especifica√ß√£o do enunciado: **"Ler do disco um lote inicial de programas previamente definido. N√£o √© permitida chegada de novos processos durante a execu√ß√£o."**

O simulador carrega **9 processos** do disco antes de iniciar a execu√ß√£o. Nenhum processo novo √© criado durante a simula√ß√£o.

| Processo | PID | Arquivo JSON | Descri√ß√£o | Instru√ß√µes | Prioridade |
|----------|-----|--------------|-----------|------------|------------|
| Quick | 1 | `process_quick.json` | Processo r√°pido (baseline) | 5 | 1 (alta) |
| Short | 2 | `process_short.json` | Processo curto | 5 | 2 |
| Medium | 3 | `process_medium.json` | Processo m√©dio | 5 | 2 |
| Long | 4 | `process_long.json` | Processo longo | 5 | 1 (alta) |
| CPU-Bound | 5 | `process_cpu_bound.json` | Uso intensivo de CPU | 5 | 3 (baixa) |
| IO-Bound | 6 | `process_io_bound.json` | Muitas requisi√ß√µes I/O | 5 | 1 (alta) |
| Memory-Intensive | 7 | `process_memory_intensive.json` | Muitos acessos √† mem√≥ria | 5 | 2 |
| Balanced | 8 | `process_balanced.json` | Carga balanceada | 5 | 2 |
| Loop-Heavy | 9 | `process_loop_heavy.json` | Loop intenso (preemp√ß√£o) | **100** | 2 |

**Caracter√≠sticas dos Processos:**

1. **Quick/Short/Medium/Long**: Processos baseline com diferentes tempos esperados
2. **CPU-Bound**: Muitas opera√ß√µes aritm√©ticas (ADD, SUB, MUL)
3. **IO-Bound**: Muitas instru√ß√µes PRINT (requisi√ß√µes de I/O)
4. **Memory-Intensive**: Muitas instru√ß√µes LOAD/STORE
5. **Balanced**: Mix equilibrado de opera√ß√µes
6. **Loop-Heavy**: 100 instru√ß√µes ADD para demonstrar preemp√ß√£o no Round Robin

**Estrutura dos Arquivos:**

`processes/process_*.json` (configura√ß√£o do PCB):
```json
{
  "pid": 1,
  "name": "Quick Process",
  "priority": 1,
  "quantum": 5,
  "arrival_time": 0
}
```

`tasks/tasks_*.json` (programa MIPS):
```json
{
  "program": [
    { "instruction": "li", "rt": "$t0", "immediate": 10 },
    { "instruction": "li", "rt": "$t1", "immediate": 20 },
    { "instruction": "add", "rd": "$t2", "rs": "$t0", "rt": "$t1" },
    { "instruction": "print", "rt": "$t2" },
    { "instruction": "end" }
  ]
}
```

**Carregamento (em `src/main.cpp`):**
```cpp
void load_processes(std::vector<std::unique_ptr<PCB>>& process_list,
                    MemoryManager& memManager) {
    // Carrega TODOS os 9 processos antes de iniciar
    for (int i = 1; i <= 9; i++) {
        auto process = std::make_unique<PCB>();
        load_pcb_from_json($"process_{name}.json", *process);
        loadJsonProgram($"tasks_{name}.json", memManager, *process, base_addr);
        process_list.push_back(std::move(process));
    }
    // Nenhum processo novo √© criado ap√≥s este ponto
}
```

---

## Estrutura do Projeto

```
SO-SimuladorVonNeumann/
‚îú‚îÄ‚îÄ CMakeLists.txt                    # Build system principal
‚îú‚îÄ‚îÄ Makefile                          # Wrapper para comandos comuns
‚îú‚îÄ‚îÄ README.md                         # Este documento
‚îú‚îÄ‚îÄ RESUMO_MUDAN√áAS.md               # Log de altera√ß√µes
‚îú‚îÄ‚îÄ LICENSE                           # Licen√ßa MIT
‚îú‚îÄ‚îÄ enunciado.pdf                     # Especifica√ß√£o do trabalho
‚îÇ
‚îú‚îÄ‚îÄ src/                              # C√≥digo-fonte C++
‚îÇ   ‚îú‚îÄ‚îÄ main.cpp                      # Ponto de entrada principal
‚îÇ   ‚îú‚îÄ‚îÄ cpu/                          # Componentes da CPU
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CONTROL_UNIT.cpp/.hpp     # Unidade de controle (pipeline)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PCB.hpp                   # Process Control Block
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ REGISTER_BANK.cpp/.hpp    # Banco de 32 registradores
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ REGISTER.cpp/.hpp         # Registrador individual
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HASH_REGISTER.hpp         # Mapa de nomes $t0 ‚Üí √≠ndice
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ULA.cpp/.hpp              # Unidade L√≥gica Aritm√©tica
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FETCH.cpp/.hpp            # Est√°gio Fetch (IF)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DECODE.cpp/.hpp           # Est√°gio Decode (ID)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EXECUTE.cpp/.hpp          # Est√°gio Execute (EX)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MEMORY_ACCESS.cpp/.hpp    # Est√°gio Memory (MEM)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WRITE_BACK.cpp/.hpp       # Est√°gio WriteBack (WB)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Scheduler.cpp/.hpp        # Escalonador (4 pol√≠ticas)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CPUMetrics.cpp/.hpp       # M√©tricas de desempenho
‚îÇ   ‚îú‚îÄ‚îÄ memory/                       # Gerenciamento de mem√≥ria
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MemoryManager.cpp/.hpp    # Gerenciador central
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Cache.cpp/.hpp            # Cache L1 (FIFO/LRU)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cachePolicy.cpp/.hpp      # Pol√≠ticas de substitui√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SegmentTable.hpp          # Tabela de segmentos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SegmentedAddressing.hpp   # Codifica√ß√£o de endere√ßos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MemoryUsageTracker.hpp    # Rastreamento temporal
‚îÇ   ‚îú‚îÄ‚îÄ IO/                           # Sistema de I/O
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Disk.cpp/.hpp             # Simula√ß√£o de disco
‚îÇ   ‚îî‚îÄ‚îÄ parser_json/                  # Leitor de JSON
‚îÇ       ‚îî‚îÄ‚îÄ JsonParser.cpp/.hpp       # Parsing de configura√ß√µes
‚îÇ
‚îú‚îÄ‚îÄ processes/                        # Configura√ß√µes PCB (JSON)
‚îÇ   ‚îú‚îÄ‚îÄ process_quick.json            # Processo 1
‚îÇ   ‚îú‚îÄ‚îÄ process_short.json            # Processo 2
‚îÇ   ‚îú‚îÄ‚îÄ process_medium.json           # Processo 3
‚îÇ   ‚îú‚îÄ‚îÄ process_long.json             # Processo 4
‚îÇ   ‚îú‚îÄ‚îÄ process_cpu_bound.json        # Processo 5
‚îÇ   ‚îú‚îÄ‚îÄ process_io_bound.json         # Processo 6
‚îÇ   ‚îú‚îÄ‚îÄ process_memory_intensive.json # Processo 7
‚îÇ   ‚îú‚îÄ‚îÄ process_balanced.json         # Processo 8
‚îÇ   ‚îî‚îÄ‚îÄ process_loop_heavy.json       # Processo 9
‚îÇ
‚îú‚îÄ‚îÄ tasks/                            # Programas MIPS (JSON)
‚îÇ   ‚îú‚îÄ‚îÄ tasks_quick.json              # 5 instru√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ tasks_short.json              # 5 instru√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ tasks_medium.json             # 5 instru√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ tasks_long.json               # 5 instru√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ tasks_cpu_bound.json          # 5 instru√ß√µes (ALU)
‚îÇ   ‚îú‚îÄ‚îÄ tasks_io_bound.json           # 5 instru√ß√µes (I/O)
‚îÇ   ‚îú‚îÄ‚îÄ tasks_memory_intensive.json   # 5 instru√ß√µes (MEM)
‚îÇ   ‚îú‚îÄ‚îÄ tasks_balanced.json           # 5 instru√ß√µes (mix)
‚îÇ   ‚îî‚îÄ‚îÄ tasks_loop_heavy.json         # 100 instru√ß√µes (loop)
‚îÇ
‚îú‚îÄ‚îÄ scripts/                          # Ferramentas de an√°lise
‚îÇ   ‚îú‚îÄ‚îÄ compare_schedulers.py         # Compara pol√≠ticas
‚îÇ   ‚îú‚îÄ‚îÄ plot_memory.py                # Gr√°ficos de mem√≥ria
‚îÇ   ‚îú‚îÄ‚îÄ plot_results.py               # Gr√°ficos gerais
‚îÇ   ‚îú‚îÄ‚îÄ generate_all_plots.sh         # Script mestre
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt              # Depend√™ncias Python
‚îÇ
‚îú‚îÄ‚îÄ build/                            # Diret√≥rio de build (gerado)
‚îÇ   ‚îú‚îÄ‚îÄ simulador                     # Execut√°vel principal
‚îÇ   ‚îú‚îÄ‚îÄ test_*                        # Execut√°veis de teste
‚îÇ   ‚îú‚îÄ‚îÄ processes/                    # C√≥pia dos JSONs
‚îÇ   ‚îú‚îÄ‚îÄ tasks/                        # C√≥pia dos JSONs
‚îÇ   ‚îî‚îÄ‚îÄ output/                       # Resultados gerados
‚îÇ       ‚îú‚îÄ‚îÄ resultados*.dat           # Relat√≥rios de escalonamento
‚îÇ       ‚îú‚îÄ‚îÄ comparacao_escalonadores*.txt # Compara√ß√µes
‚îÇ       ‚îú‚îÄ‚îÄ memory_usage_*.txt        # Relat√≥rios individuais (9)
‚îÇ       ‚îî‚îÄ‚îÄ memory_aggregated_report.txt # Relat√≥rio agregado
‚îÇ
‚îî‚îÄ‚îÄ plots/                            # Gr√°ficos gerados (12 arquivos)
    ‚îú‚îÄ‚îÄ scheduler_time_comparison.png
    ‚îú‚îÄ‚îÄ scheduler_efficiency_comparison.png
    ‚îú‚îÄ‚îÄ scheduler_radar_comparison.png
    ‚îú‚îÄ‚îÄ memory_usage_timeline.png
    ‚îú‚îÄ‚îÄ cache_hit_rate_evolution.png
    ‚îú‚îÄ‚îÄ memory_heatmap.png
    ‚îú‚îÄ‚îÄ pipeline_cycles.png
    ‚îú‚îÄ‚îÄ memory_accesses.png
    ‚îú‚îÄ‚îÄ execution_times.png
    ‚îú‚îÄ‚îÄ cache_performance.png
    ‚îú‚îÄ‚îÄ comparison_matrix.png
    ‚îî‚îÄ‚îÄ memory_final_summary.png
```

---

## Decis√µes de Projeto e Justificativas

### 1. Arquitetura Multicore Real (C++ Threads)

**Decis√£o:** Usar `std::thread` para implementar m√∫ltiplos cores.

**Justificativa:**
- Execu√ß√£o paralela verdadeira (n√£o simulada)
- Sincroniza√ß√£o com mutexes para mem√≥ria compartilhada
- Demonstra conceitos reais de sistemas operacionais
- Permite an√°lise de speedup real vs single-core

**Alternativas consideradas:**
- Simula√ß√£o sequencial (n√£o demonstraria paralelismo real)
- Processos UNIX (overhead muito alto)

### 2. Pipeline MIPS de 5 Est√°gios

**Decis√£o:** Implementar pipeline completo (IF ‚Üí ID ‚Üí EX ‚Üí MEM ‚Üí WB).

**Justificativa:**
- Conformidade com arquitetura MIPS cl√°ssica
- Demonstra conceito de pipeline em CPU real
- Permite an√°lise de ciclos por instru√ß√£o
- Base para extens√µes futuras (hazards, forwarding)

**Alternativas consideradas:**
- Execu√ß√£o direta (n√£o representaria arquitetura real)
- Pipeline simplificado (perderia detalhes t√©cnicos)

### 3. Segmenta√ß√£o (Modelo Tanenbaum)

**Decis√£o:** 4 segmentos (CODE, DATA, STACK, HEAP) com prote√ß√£o.

**Justificativa:**
- Modelo cl√°ssico de Tanenbaum (livro texto)
- Prote√ß√£o de c√≥digo (read-only)
- Endere√ßamento l√≥gico realista (32 bits)
- Preparado para pagina√ß√£o futura

**Alternativas consideradas:**
- Pagina√ß√£o pura (mais complexo para escopo do trabalho)
- Endere√ßamento plano (n√£o demonstraria conceitos de SO)

### 4. Cache L1 com FIFO e LRU

**Decis√£o:** Duas pol√≠ticas de substitui√ß√£o compar√°veis.

**Justificativa:**
- FIFO: baseline simples (O(1))
- LRU: pol√≠tica realista usada em processadores reais
- Permite an√°lise comparativa de desempenho
- Demonstra impacto de pol√≠ticas na taxa de hit

**Alternativas consideradas:**
- Apenas FIFO (n√£o mostraria melhorias)
- Pol√≠ticas mais complexas (CLOCK, LFU) - fora do escopo

### 5. Quantum de 5 Ciclos (Round Robin)

**Decis√£o:** Quantum fixo de 5 ciclos de pipeline.

**Justificativa:**
- Demonstra preemp√ß√£o com processo Loop-Heavy (100 instru√ß√µes)
- Quantum pequeno: maior interatividade
- Permite observar overhead de context switch
- Compar√°vel com sistemas operacionais reais (Linux: 100ms ‚âà milh√µes de ciclos)

**Alternativas consideradas:**
- Quantum de 1 ciclo (overhead excessivo)
- Quantum de 50 ciclos (n√£o demonstraria preemp√ß√£o)

### 6. Rastreamento Temporal (Snapshots a cada 10 ciclos)

**Decis√£o:** Capturar estado de mem√≥ria periodicamente.

**Justificativa:**
- Atende requisito: "utiliza√ß√£o de mem√≥ria ao longo do tempo"
- Intervalo de 10 ciclos: granularidade adequada
- N√£o impacta performance (baixo overhead)
- Permite an√°lise temporal e gera√ß√£o de gr√°ficos

**Alternativas consideradas:**
- Snapshot a cada ciclo (overhead excessivo, dados redundantes)
- Apenas snapshot final (n√£o mostraria evolu√ß√£o temporal)

### 7. JSON para Configura√ß√£o

**Decis√£o:** Processos e tarefas definidos em JSON.

**Justificativa:**
- Formato estruturado e leg√≠vel
- F√°cil modifica√ß√£o sem recompilar
- Separa√ß√£o de c√≥digo e dados
- Suporte a lote inicial (9 processos)

**Alternativas consideradas:**
- C√≥digo hardcoded (inflex√≠vel)
- Entrada manual (n√£o reproduz√≠vel)

### 8. Python para Visualiza√ß√£o

**Decis√£o:** Scripts Python com matplotlib para gr√°ficos.

**Justificativa:**
- matplotlib: biblioteca padr√£o para gr√°ficos cient√≠ficos
- Python: ampla ado√ß√£o em an√°lise de dados
- Separa√ß√£o de l√≥gica (C++) e apresenta√ß√£o (Python)
- 12 gr√°ficos gerados automaticamente

**Alternativas consideradas:**
- Integrar gr√°ficos no C++ (depend√™ncias pesadas)
- Apenas texto (menos visual)

---

## Tecnologias Utilizadas

### Linguagens
- **C++17** - Linguagem principal do simulador
- **Python 3.8+** - Scripts de visualiza√ß√£o
- **Bash** - Automa√ß√£o de build e testes

### Bibliotecas e Frameworks
- **STL (Standard Template Library)**
  - `<thread>` - Multithreading para multicore
  - `<mutex>` - Sincroniza√ß√£o de mem√≥ria compartilhada
  - `<atomic>` - Opera√ß√µes at√¥micas
  - `<chrono>` - Medi√ß√£o de tempo
  - `<vector>`, `<map>`, `<queue>` - Estruturas de dados
  
- **nlohmann/json** - Parsing de arquivos JSON
- **pthread** - Threads POSIX (backend do std::thread)

### Ferramentas Python
- **matplotlib** - Gera√ß√£o de gr√°ficos
- **numpy** - C√°lculos num√©ricos
- **pandas** (opcional) - An√°lise de dados

### Build System
- **CMake 3.10+** - Configura√ß√£o de build multiplataforma
- **GNU Make** - Wrapper para comandos comuns
- **GCC 9+ / Clang 10+** - Compiladores C++ com suporte a C++17

### Controle de Vers√£o
- **Git** - Versionamento de c√≥digo

### Ambiente de Desenvolvimento
- **Linux Ubuntu 20.04+** - Sistema operacional alvo
- **VS Code / CLion** - IDEs sugeridas
- **GDB** - Debugging
- **Valgrind** - Detec√ß√£o de memory leaks

---

## Equipe de Desenvolvimento

- Jo√£o Pedro Rodrigues Silva ([jottynha](https://github.com/Jottynha))
- Eduardo da Silva Torres Grillo ([EduardoGrillo](https://github.com/EduardoGrillo))
- Samuel Silva Gomes ([samuelsilvg](https://github.com/samuelsilvg))
- Jader Oliveira Silva ([0livas](https://github.com/0livas))


## üìÑ Licen√ßa

Este projeto √© licenciado sob a **MIT License** - veja o arquivo [LICENSE](LICENSE) para detalhes.

```
MIT License

Copyright (c) 2025 CEFET-MG - Simulador Multicore Von Neumann

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## üìö Refer√™ncias Bibliogr√°ficas

1. **TANENBAUM, Andrew S.; BOS, Herbert.** *Modern Operating Systems.* 4th ed. Pearson, 2014.
   - Cap√≠tulo 3: Memory Management (Segmentation)
   - Cap√≠tulo 2: Processes and Threads (Scheduling)

2. **PATTERSON, David A.; HENNESSY, John L.** *Computer Organization and Design: The Hardware/Software Interface.* 5th ed. Morgan Kaufmann, 2013.
   - Cap√≠tulo 4: The Processor (MIPS Pipeline)
   - Cap√≠tulo 5: Memory Hierarchy

3. **STALLINGS, William.** *Operating Systems: Internals and Design Principles.* 9th ed. Pearson, 2017.
   - Cap√≠tulo 9: Uniprocessor Scheduling
   - Cap√≠tulo 7: Memory Management

4. **SILBERSCHATZ, Abraham; GALVIN, Peter B.; GAGNE, Greg.** *Operating System Concepts.* 10th ed. Wiley, 2018.
   - Cap√≠tulo 6: CPU Scheduling
   - Cap√≠tulo 9: Virtual Memory

5. **HENNESSY, John L.; PATTERSON, David A.** *Computer Architecture: A Quantitative Approach.* 6th ed. Morgan Kaufmann, 2017.
   - Ap√™ndice C: Pipelining

6. **Documenta√ß√£o nlohmann/json:** https://github.com/nlohmann/json
   - Parsing de JSON em C++

7. **CPPReference - std::thread:** https://en.cppreference.com/w/cpp/thread/thread
   - Multithreading em C++17

8. **Matplotlib Documentation:** https://matplotlib.org/stable/contents.html
   - Gera√ß√£o de gr√°ficos cient√≠ficos

---



